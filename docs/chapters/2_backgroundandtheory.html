<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Learning Morpho-phonological Alternations like French Liaison - 2&nbsp; Background and Theoretical Framework</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/3_methods.html" rel="next">
<link href="../chapters/1_introduction.html" rel="prev">
<link href="../resources/favicon.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<meta name="citation_title" content="Learning Morpho-phonological Alternations like French Liaison: an Artificial Language Learning Study">
<meta name="citation_author" content="Zara Khalaji Pirbaluti">
<meta name="citation_fulltext_html_url" content="http://hdl.handle.net/2429/90893">
<meta name="citation_language" content="en">
<meta name="citation_dissertation_institution" content="University of British Columbia">
<meta name="citation_reference" content="citation_title=Distributional cues and the onset bias in early word segmentation.;,citation_author=Mireille Babineau;,citation_author=Rushen Shi;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=https://doi.apa.org/doi/10.1037/a0038105;,citation_issue=12;,citation_doi=10.1037/a0038105;,citation_volume=50;,citation_language=en;,citation_journal_title=Developmental Psychology;">
<meta name="citation_reference" content="citation_title=Phonologically Conditioned Allomorph Selection: Phonologically Conditioned Allomorph Selection;,citation_author=Andrew Nevins;,citation_editor=Marc Van Oostendorp;,citation_editor=Colin J. Ewen;,citation_editor=Elizabeth Hume;,citation_editor=Keren Rice;,citation_publication_date=2011-04-28;,citation_cover_date=2011-04-28;,citation_year=2011;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/10.1002/9781444335262.wbctp0099;,citation_doi=10.1002/9781444335262.wbctp0099;,citation_volume=Volume IV. Phonological Interfaces;,citation_language=en;,citation_inbook_title=undefined;">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/2_backgroundandtheory.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Background and Theoretical Framework</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Learning Morpho-phonological Alternations like French Liaison</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/gazellarium/ALL-FrL" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../Learning-Morpho-phonological-Alternations-like-French-Liaison.epub" title="Download ePub" class="quarto-navigation-tool px-1" aria-label="Download ePub"><i class="bi bi-journal"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/0_abstract.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Abstract</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/1_introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/2_backgroundandtheory.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Background and Theoretical Framework</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/3_methods.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/4_results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/5_discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliography</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Stimuli List</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/appendix2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Statistical Summaries</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction-to-phonologically-conditioned-allomorphy" id="toc-introduction-to-phonologically-conditioned-allomorphy" class="nav-link active" data-scroll-target="#introduction-to-phonologically-conditioned-allomorphy"><span class="header-section-number">2.1</span> Introduction to phonologically conditioned allomorphy</a></li>
  <li><a href="#french-liaison" id="toc-french-liaison" class="nav-link" data-scroll-target="#french-liaison"><span class="header-section-number">2.2</span> French liaison</a></li>
  <li><a href="#developmental-path-of-morpho-phonological-acquisition-and-the-literature-on-child-acquisition-of-liaison" id="toc-developmental-path-of-morpho-phonological-acquisition-and-the-literature-on-child-acquisition-of-liaison" class="nav-link" data-scroll-target="#developmental-path-of-morpho-phonological-acquisition-and-the-literature-on-child-acquisition-of-liaison"><span class="header-section-number">2.3</span> Developmental path of morpho-phonological acquisition and the literature on child acquisition of liaison</a></li>
  <li><a href="#learnability-of-liaison-as-a-morpheme-specific-phonological-phenomenon-within-optimality-theory" id="toc-learnability-of-liaison-as-a-morpheme-specific-phonological-phenomenon-within-optimality-theory" class="nav-link" data-scroll-target="#learnability-of-liaison-as-a-morpheme-specific-phonological-phenomenon-within-optimality-theory"><span class="header-section-number">2.4</span> Learnability of liaison as a morpheme-specific phonological phenomenon within Optimality Theory</a>
  <ul>
  <li><a href="#learning-the-underlying-representation" id="toc-learning-the-underlying-representation" class="nav-link" data-scroll-target="#learning-the-underlying-representation"><span class="header-section-number">2.4.1</span> Learning the underlying representation</a></li>
  <li><a href="#initial-state-grammar-to-end-state-grammar" id="toc-initial-state-grammar-to-end-state-grammar" class="nav-link" data-scroll-target="#initial-state-grammar-to-end-state-grammar"><span class="header-section-number">2.4.2</span> Initial state grammar to end state grammar</a></li>
  </ul></li>
  <li><a href="#predictions-of-the-learning-theory-in-the-current-study" id="toc-predictions-of-the-learning-theory-in-the-current-study" class="nav-link" data-scroll-target="#predictions-of-the-learning-theory-in-the-current-study"><span class="header-section-number">2.5</span> Predictions of the learning theory in the current study</a>
  <ul>
  <li><a href="#ordered-learning-trajectory---liaison-first" id="toc-ordered-learning-trajectory---liaison-first" class="nav-link" data-scroll-target="#ordered-learning-trajectory---liaison-first"><span class="header-section-number">2.5.1</span> Ordered learning trajectory - Liaison first</a></li>
  <li><a href="#ordered-learning-trajectory---non-liaison-first" id="toc-ordered-learning-trajectory---non-liaison-first" class="nav-link" data-scroll-target="#ordered-learning-trajectory---non-liaison-first"><span class="header-section-number">2.5.2</span> Ordered learning trajectory - Non-liaison first</a></li>
  <li><a href="#mixed-learning-trajectory" id="toc-mixed-learning-trajectory" class="nav-link" data-scroll-target="#mixed-learning-trajectory"><span class="header-section-number">2.5.3</span> Mixed Learning trajectory</a></li>
  <li><a href="#predicted-outcomes-of-trajectories" id="toc-predicted-outcomes-of-trajectories" class="nav-link" data-scroll-target="#predicted-outcomes-of-trajectories"><span class="header-section-number">2.5.4</span> Predicted outcomes of trajectories</a>
  <ul class="collapse">
  <li><a href="#predictions-for-an-optimal-learner" id="toc-predictions-for-an-optimal-learner" class="nav-link" data-scroll-target="#predictions-for-an-optimal-learner">Predictions for an optimal learner</a></li>
  <li><a href="#predictions-for-a-suboptimal-learner" id="toc-predictions-for-a-suboptimal-learner" class="nav-link" data-scroll-target="#predictions-for-a-suboptimal-learner">Predictions for a suboptimal learner</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Background and Theoretical Framework</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction-to-phonologically-conditioned-allomorphy" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="introduction-to-phonologically-conditioned-allomorphy"><span class="header-section-number">2.1</span> Introduction to phonologically conditioned allomorphy</h2>
<p>Allomorphy refers to the variations in a morpheme’s phonological form, often controlled by contextual linguistic factors arising from morpho-syntax or morpho-phonology. The allomorph variants of a morpheme can exhibit various degrees of phonological dissimilarity and idiosyncrasy. For example, the verb <em>to be</em> in English presents three dissimilar forms in the present tense (<em>am/is/are</em>) that are morphologically conditioned and somewhat idiosyncratic, as the choices are not consistent across person and number. In contrast, the two indefinite article forms in English (<em>a/an</em>) are more phonologically similar and demonstrate regular conditioning, as the choice depends on whether the noun begins with a vowel or consonant. The latter example is commonly referred to as phonologically conditioned allomorphy (PCA), where the phonological context determines the selection of the allomorph. In such cases, the allomorphs selected can often be considered as optimizing and motivated by avoiding marked phonological structure (cf.&nbsp;“non-optimizing phonologically conditioned suppletive allomorphy” in Paster, 2006: 76-97). Nevins (2011) outlines six types of phonological conditions that lead to optimized and natural outputs. The most prevalent type involves conditions that produce optimized (unmarked) syllable structures, ranging from preference for onsets, dispreference for codas, or sonority drops in codas (for a comprehensive review, see Nevins, 2011: 6-8; Paster, 2006: 63-71). Besides at the level of syllable structure, other types of phonological conditions can appear at the level of segments or prosody.</p>
<p>The next section will introduce the case study focusing on a phonologically conditioned allomorphy phenomenon in French. French liaison presents challenges regarding the phonological conditions governing allomorph selection and representations which will have consequences for learning.</p>
</section>
<section id="french-liaison" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="french-liaison"><span class="header-section-number">2.2</span> French liaison</h2>
<p>Liaison is a frequent and widespread morpho-phonological phenomenon in French which has received great attention over the years in the study of the phonological grammar of French (Storme, 2024; Smolensky and Goldrick, 2016; Tranel, 2000; Selkirk, 1974). In terms of its domain, it is categorized as <em>external allomorphy</em> where the conditioning factors are determined by phonological information in adjacent words in the higher prosodic domain. In this respect, liaison is also known as an <em>external sandhi</em> phenomenon , since the alternation occurs at the boundary of two words. The locus of liaison is limited to certain syntactic configurations; at the same time, it is also affected by variation and sociolinguistic variables (Meinschaefer, Sven and Frisch, 2015; Durand and Lyche, 2008). The following data points illustrate the basic pattern in prenominal configurations. The examples (1−4) are of noun phrases with two syntactic configurations in&nbsp;which liaison applies, including [determiner + noun] and [adjective + noun] such as (1) the plural definite article <em>les</em> with the allomorphs [le]/[le<strong>z</strong>], (2) the masculine singular indefinite article <em>un</em> with the allomorphs [œ̃]/[œ̃<strong>n</strong>], (3) the numeral modifier <em>deux</em> ‘two’ with [dø]/[dø<strong>z</strong>] and (4) the masculine singular adjective <em>petit</em> ‘little’ with [pəti]/[pəti<strong>t</strong>]:</p>
<table class="table">
<colgroup>
<col style="width: 5%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 11%">
<col style="width: 5%">
<col style="width: 14%">
<col style="width: 16%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">(1)</th>
<th></th>
<th></th>
<th></th>
<th style="text-align: left;">(2)</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">a.</td>
<td><em><strong>les</strong> bébés</em></td>
<td>[le.be.be]</td>
<td>‘the babies’</td>
<td style="text-align: left;">a.</td>
<td><em><strong>un</strong> bébé</em></td>
<td>[œ̃.be.be]</td>
<td>‘a baby’</td>
</tr>
<tr class="even">
<td style="text-align: left;">b.</td>
<td><em><strong>les</strong> amis</em></td>
<td>[le.<strong>z</strong>a.mi]</td>
<td>‘the friends’</td>
<td style="text-align: left;">b.</td>
<td><em><strong>un</strong> ami</em></td>
<td>[œ̃.<strong>n</strong>a.mi]</td>
<td>‘a friend’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">c.</td>
<td><em><strong>les</strong> ours</em></td>
<td>[le.<strong>z</strong>u.ʁs]</td>
<td>‘the bears’</td>
<td style="text-align: left;">c.</td>
<td><em><strong>un</strong> ours</em></td>
<td>[œ̃.<strong>n</strong>uʁs]</td>
<td>‘a bear’</td>
</tr>
<tr class="even">
<td style="text-align: left;">(3)</td>
<td></td>
<td></td>
<td></td>
<td style="text-align: left;">(4)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td style="text-align: left;">a.</td>
<td><em><strong>deux</strong> bébés</em></td>
<td>[dø.be.be]</td>
<td>‘two babies’</td>
<td style="text-align: left;">a.</td>
<td><em><strong>petit</strong> bébé</em></td>
<td>[pə.ti.be.be]</td>
<td>‘little baby’</td>
</tr>
<tr class="even">
<td style="text-align: left;">b.</td>
<td><em><strong>deux</strong> amis</em></td>
<td>[dø.<strong>z</strong>a.mi]</td>
<td>‘two friends’</td>
<td style="text-align: left;">b.</td>
<td><em><strong>petit</strong> ami</em></td>
<td>[pə.ti.<strong>t</strong>a.mi]</td>
<td>‘little friend’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">c.</td>
<td><em><strong>deux</strong> ours</em></td>
<td>[dø.<strong>z</strong>uʁs]</td>
<td>‘two bears’</td>
<td style="text-align: left;">c.</td>
<td><em><strong>petit</strong> ours</em></td>
<td>[pə.ti.<strong>t</strong>uʁs]</td>
<td>‘little bear’</td>
</tr>
</tbody>
</table>
<p>The final consonant, here [z, n, t] in bold, in the VC# allomorphs is referred to as the “liaison consonant” (LC) in the literature. The basic generalization in these examples is that some structural property of the following words determine the presence of the allomorph containing the liaison consonant or lack thereof. As examples (a-c) for each allomorph set show, the onset of the left word (nouns) seems to be conditioning the choice of the allomorph in the right morpheme. Examples (a) are C-initial nouns, resulting in the selection of the V-final allomorph. In contrast, examples (b) and (c) demonstrate V-initial nouns, which results in the allomorph containing the liaison consonant.</p>
<p>To fully understand the role of this pattern in the morpho-phonological system of French, it is essential to recognize that morphemes with allomorph pairs, that is those involved in liaison, are lexically determined and do not constitute a coherent class. According to Côté (2011: 5) the morphemes grouped under liaison are argued to be either among closed lexical classes or specific morphological categories. The determiners (1−2) are an example of the closed class of morphemes, other functional morphemes in this category are clitics, conjunctions, and prepositions. The specific morphological categories include adjectives, nouns, adverbs, within compounds and fixed phrases. However, it is crucial to note that this is not a language-wide pattern; for instance, not all [adjective + noun] configurations in French follow the same pattern across-the-board. The data in (5) shows two masculine adjectives which do not undergo liaison. Examples (5a) and (5b) show C-initial nouns and examples (5c) and (5d) V-initial nouns which all co-occur with non-alternating adjectives <em>joli</em> [ʒɔli] and <em>jeune</em> [ʒœn].</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 6%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">(5)</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">a.</td>
<td><em><strong>joli</strong> bébé</em></td>
<td>[ʒɔli.be.be]</td>
<td>‘pretty baby’</td>
<td>b.</td>
<td><em><strong>jeune</strong> bébé</em></td>
<td>[ʒœn.be.be]</td>
<td>‘young baby’</td>
</tr>
<tr class="even">
<td style="text-align: left;">c.</td>
<td><em><strong>joli</strong> ami</em></td>
<td>[ʒɔli.a.mi]</td>
<td>‘pretty friend’</td>
<td>d.</td>
<td><em><strong>jeune</strong> ami</em></td>
<td>[ʒœ.na.mi]</td>
<td>‘young friend’</td>
</tr>
</tbody>
</table>
<p>The contrast in examples (4 vs.&nbsp;5) illustrate an important empirical pattern to be captured, whereby a situation is created for phonological processes favouring naturally well-formed structures in an allomorph to be restricted to only certain morphemes. The nature of these restrictions appears quite arbitrary which even seems to be insensitive to the morpho-syntactic categories of morphemes. This is evident from the fact that certain groups of prenominal adjectives possess allomorphic pairs (4), while others do not (5).</p>
<p>From the point of view of acquisition, it is worth mentioning that the right words also contribute to creating added irregularities in the pattern. Therefore, considering the phenomenon as a whole, idiosyncratic and morpheme-specific characteristics extend to the right words which were introduced as the conditioning factor. Examples in (6) illustrate that certain nouns traditionally categorized as <em>h-aspiré</em> are anticipated to condition the C-final allomorph but in fact resist it (for a review of historical facts see Southworth, 1970). A small group of words such as <em>homard</em>, <em>h</em>é<em>ros</em>, and <em>hibou</em> which phonologically begin with a vowel in modern French, function as if they are C-initial, thereby not selecting the allomorph containing the liaison consonant (cf.&nbsp;examples b and c in 1−4). Therefore, in the event that a h-aspiré noun constitutes the context in prenominal liaison, the basic generalization does not hold and the regular phonological sensitivity of the plural definite morpheme is neutralized.</p>
<table class="table">
<colgroup>
<col style="width: 14%">
<col style="width: 22%">
<col style="width: 16%">
<col style="width: 24%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">(6)</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">a.</td>
<td><em>les <strong>homards</strong></em></td>
<td>[le.ɔm.aʁ]</td>
<td>*[le.<strong>z</strong>ɔm.aʁ]</td>
<td>‘the lobsters’</td>
</tr>
<tr class="even">
<td style="text-align: left;">b.</td>
<td><em>les <strong>héros</strong></em></td>
<td>[le.eʁo]</td>
<td>*[le.<strong>z</strong>eʁo]</td>
<td>‘the heroes’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">c.</td>
<td><em>les <strong>hiboux</strong></em></td>
<td>[le.ibu]</td>
<td>*[le.<strong>z</strong>ibu]</td>
<td>‘the owls’</td>
</tr>
</tbody>
</table>
<p>After having examined the basic synchronic patterns and characteristics of morphemes within the higher prosodic domain where liaison occurs, it must be noted that the system of liaison has evolved over hundreds of years (Morin, 2005). The idiosyncratic nature and irregularities observed are largely attributed to diachronic factors. Overall, the irregular interactions between phonological elements and morphology give rise to various analyses and competing theories concerning the organization of grammar. Several accounts have also been proposed about the affiliation of the liaison consonant (for a summary see Côté, 2011: 8; Tessier et al., 2023: 3; Storme, 2024: 31) where it could be associated with the word1 (e.g., <em>les</em>), word2 (e.g., <em>ami</em>), both or neither. This system of liaison, shaped by both synchronic and diachronic influences, has sparked debates regarding the mechanisms of allomorphy selection. Some accounts emphasize morphological listing (Paster, 2006; Embick, 2010), while others such as Smith (2015) advocate for constraint-based models where the ranking of phonological and morphological constraints select the underlying representations. As Nevins (2011: 23) notes, using artificial language acquisition experiments where “diachrony is fully controlled by the experimenter and nonetheless the learner demonstrates the emergence of a preference for phonological optimization based on sparse or insufficient data” can be a good test bed for this debate.</p>
<p>In the next section, to shed some light on the extent to which the role of phonology is central in speakers’ minds, the literature on children’s acquisition of French liaison is reviewed to discuss different approaches explaining empirical results in experimental studies with young children. Additionally, a brief overview of developmental stages in morphophonemic learning is provided.</p>
</section>
<section id="developmental-path-of-morpho-phonological-acquisition-and-the-literature-on-child-acquisition-of-liaison" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="developmental-path-of-morpho-phonological-acquisition-and-the-literature-on-child-acquisition-of-liaison"><span class="header-section-number">2.3</span> Developmental path of morpho-phonological acquisition and the literature on child acquisition of liaison</h2>
<p>It is generally accepted that early in the developmental path of phonological acquisition infants exhibit signs of developing sensitivity to phonotactic patterns, allowing them to build their foundational phonological knowledge by 8 to 12 months of age (for a recent review, see Sundara et al., 2022; Jusczyk, 2000). Learning about alternations typically occurs later, starting around 12 months (White and Sundara, 2014). Perception studies support this notion, revealing that infants (approximately 9 months old) can distinguish phonotactic probabilities among words (Friederici and Wessels, 1993) and employ this distributional information for word segmentation (Mattys and Jusczyk, 2001), as well as for learning (voicing) alternations (White et al., 2008). A longitudinal study by Luckaszewicz (2006) reports that a child aged 3;5-8 was more successful at mastering alternations that reflect the phonotactic rules of Polish than those found only in specific morphemes. These studies suggest that phonotactic knowledge may play a crucial role in guiding the subsequent learning of alternations. Further along the developmental path, evidence regarding infants’ receptive morphological knowledge indicates that they display sensitivity to morpho-phonological patterns in their second year of life, well before they achieve mastery of these patterns in later stages (Soderstrom et al., 2007). Understanding morpho-phonological alternations involves mapping variations in surface forms to underlying representations and recognizing morphemes’ distinct meanings. In this context, the literature on morphological acquisition illustrates that the discovery of meaning influences infants’ acquisition of suffixes (Mintz, 2013). However, more recent experiments reveal that children’s knowledge of morphology develops concurrently with their understanding of phonology and semantics in English (Kim and Sundara, 2021) as well as in French (Marquis and Shi, 2012). In fact, Kim and Sundara (2021) suggest that their findings propose a potentially bidirectional relationship between the acquisition of morphology and phonology, challenging the earlier assumption that phonological acquisition solely drives morphological acquisition.</p>
<p>As Tessier (2016:1) points out, acquiring morpho-phonological patterns presents challenges both to learners and researchers as “the learner must determine a set of lexical representations attached to meanings, and also control the phonological regularities involved in the combinations of those stored representations”. In other words, morpho-phonological learning is inherently more complex than phonological learning. While it is possible to account for across-the-board phonological alternations by the phonological grammar alone, morpho-phonological patterns necessitate the integration of morphology, semantics, and phonology. For instance, consider sequences involving two morphemes verb + X, such as <em>talk</em>+[-t] and <em>log</em>+[-d]; the complexity in mastering the alternation of forms X arises from several interrelated components. It is essential to acknowledge that developmental processes are more entangled and iterative than linear in reality. These components can be learned synchronously or asynchronously, as Kim and Sundara (2021) show learning can be concurrent across domains. Regardless of the relative order of acquisition in the developmental path of learning allomorphy, the key components that an ideal learner must acquire along their path to master the variations of the English past tense suffix<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> is outlined in (7).</p>
<table class="table">
<colgroup>
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 90%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">(7)</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td>a.</td>
<td>These sequences are comprised of 2 morphemes: verb + morpheme X.</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td>b.</td>
<td>Morphemes <em>talk</em> and <em>log</em> are verbs with their respective meaning.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td>c.</td>
<td>Morphs [-t] and [-d] are similar in form (broadly speaking phonological similarity is not a requirement for allomorphs, but can be used as a cue in some cases).</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td>d.</td>
<td>Morphs [-t] and [-d] share the same meaning (or syntactic function).</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td>e.</td>
<td>Distributions of [-t] and [-d] follow a phonological pattern ([-t] after a voiceless non-sibilant C; [-d] after a V or voiced non-sibilant C).</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td>f.</td>
<td>Morphs [-t] and [-d] should be represented and stored in the lexicon as variants of one morpheme &lt;+past tense&gt; and not separately.</td>
</tr>
</tbody>
</table>
<p>In certain instances, alternations related to a morpheme may adhere to the phonotactic rules of the language. For example, the acquisition of past tense allomorphs in English aligns with learning static restrictions found in mono-morphemic nouns about similarity in voicing in sequences of adjacent obstruents. Therefore, discovering the phonological basis for these alternations can, at least theoretically, be informed and guided by phonotactic learning. Empirical support for this issue is illustrated in a series of experiments by Chong (2021) where participants learned the alternations across morpheme boundaries best when the patterns matched the stem-internal phonotactics. However, it is common for phonological alternations to be limited to specific morphemes, presenting an additional challenging component for learners to resolve along with the components in (7a−f). As discussed in the previous section, the case of French liaison exemplifies this phenomenon.</p>
<p>The latter half of this subsection focuses on the research related to the acquisition of French liaison. Various scholars have explored the early development of this morpho-phonological pattern utilizing both corpus data and experimental methodologies (Buerkin-Pontrelli et al., 2017; Demuth and Tremblay, 2008; Dugua, 2006; Chevrot and Fayol, 2001; Morel, 1994). This review will succinctly examine recent studies that aim to explain and characterize the errors associated with representations of prenominal liaison and nouns that begin with vowels.</p>
<p>Evidence from <em>perception</em> experiments using a preferential-looking paradigm, as designed by Babineau and Shi (2014), indicates that children as young as 2;0 year of age familiarized with novel pseudo-words in various liaison contexts (which could be ambiguous between being vowel-initial or consonant-initial) accepted both segmentations of pseudo-words. For instance, in case of phrases like <em>un onche</em> [œ̃.nõʃ] or <em>des onches</em> [de.zoʃ], the pseudo-word <em>onche</em> could be ambiguous between combinations of [œ̃]+[nõʃ] where the syllable boundary and word boundary are aligned or [œ̃n]+[õʃ] where they are not. In contrast, 1;8 year old children tend to segment these novel words as consonant-initial (e.g., [nõʃ], [zoʃ].). More recently, Babineau et al.&nbsp;(2023) conducted follow-up experiments using different familiarization conditions with 2;0 year olds to shed light on the nature of their knowledge regarding liaison. Specifically, the goal was to determine whether their knowledge is shaped by language-specific statistical information from sub-syllabic distributions in French or whether it is not based on language-specific information per se and is only using broad statistical sub-syllabic distributions. If the children use their language-specific knowledge they could leverage it to overcome the universal bias influencing their segmentation which aligns syllable onsets with word edges. Their findings support the notion that, at this age, infants can recognize the co-occurrence patterns particular to certain liaison consonants in French in a larger context (including the first words) from which the sub-syllabic distributions emerge while disregarding the universal segmentation bias. However, this advanced top-down processing that resembles adult understanding is not as evident in the production of the toddlers of the same age as the authors also point out. Now before turning to the two different models discussed in the literature to explain and predict the production of French-speaking children, I will summarize the main error categories and empirical facts for young children as documented in different corpora.</p>
<p>The rate of <em>production</em> errors during the first two years of life indicates that mastering liaison takes considerable time and often extends beyond two years. Buerkin-Pontrelli et al.&nbsp;(2017) analyze and report data from the Lyon corpus (Demuth and Tremblay, 2008) in CHILDES database (MacWhinney, 2000), categorizing the errors into two main types: a. those that involve phonological processes such as truncation or reduplication (e.g., les ami [le.mi] or [le.ma.mi]); and b. other errors related to the liaison consonant, such as insertion, replacement and omission (e.g., <em>joli ami</em> [ʒɔ.li.na.mi], <em>les ami</em> [le.na.mi], <em>les enfants</em> [le.ã.fã]). Their analysis reveals that during the early stages until 2;0 the errors are predominantly of a phonological nature to fill the onset positions of V-initial words or preserve minimal-foot structure. Between the ages of 2;0 to 3;0, errors involving liaison consonants appear in the children’s speech within the corpus. Further than 3;0, however, available data from one child in the corpus demonstrates that such errors are comparatively rare between the ages of 3 – 3;5. They highlight that those phonological errors (truncation and reduplication) were more common than liaison consonants errors, however the overall trajectory of the errors could suggest that as children’s phonological system stabilizes, they might produce errors which are directly due to their early awareness of liaison. One important point to keep in mind with regards to these studies is that the estimated age of mastery varies depending on whether the data is elicited or produced spontaneously. The spontaneous liaison errors documented might decrease in earlier age ranges compared to elicited errors in experimental settings that could be even found with children tested up to 5;2. Buerkin-Pontrelli et al.&nbsp;(2017) also present results from an original experiment to investigate whether 3;0 children could produce two novel vowel-initial words in both liaison and non-liaison contexts productively. Their findings reveal that 3;0 children are reaching adults’ accuracy rate in full phrase contexts, which suggests they can segment and use liaison after a brief exposure. On the other hand, two-thirds of the children’s errors involved replacements or insertions, contrasting with adults, who tended to make more errors by omitting the liaison consonant. This indicates that children struggle more than adults to provide vowel-initial forms in non-liaison-triggering contexts.</p>
<p>There are two models put forward in the literature to explain children’s acquisition of liaison. One model has examined the stages of learning liaison through a phonological lens (Buerkin-Pontrelli et al., 2017; Wauquier-Gravelines and Braud, 2005). With this model, the stages of acquisition are based on the evolution of syllabic templates. It is argued that following the maximum onset principle, children rely on distinct mechanisms in their errors to resyllabify word-final consonants in the word resulting in V.CV syllables rather than VC.V syllables. According to this model, once the phonological development is more complete, by ages 3;0 to 3;5, children can utilize morphological bootstrapping, enabling them to identify morphemes and the contexts in which particular liaison consonants (LCs) appear. The second model follows a constructionist approach (Chevrot et al., 2009) couched within usage-based theories (Tomasello, 2003) and argues that the acquisition of liaison occurs in three stages. In this framework, it is predicted that children store schemas (such as les + X, un + X) without information about the liaison consonant in determiners and alternating noun variants from 3;0 to 5;0. By the ages of 4;0 to 5;0, they begin to develop schemas that reflect the relationship between a determiner and a class of noun variants (e.g., les + /zX/, un + /nX/). As Buerkin-Pontrelli et al.&nbsp;(2017) indicate, the expected timelines for these stages in the constructionist model are not entirely precise, as children tend to exhibit fewer liaison errors after the age of 3. However, constructionist models heavily depend on input frequency, leading to the prediction that certain nouns are more closely associated with errors in singular contexts than with plural. As supported by the results of the experiment reported by Buerkin-Pontrelli et al.&nbsp;(2017), input frequency plays a role in early stages of learning; however, its role and its interaction with other aspects of learning more complicated patterns such as liaison needs further investigation.</p>
<p>In the next section, before I discuss a proposal regarding how the phonological grammar can enable the learning of liaison-like patterns—and to what extent it can do so, along with the predictions it generates for the experiment—I will first provide an overview of the nature of the learning problem.</p>
</section>
<section id="learnability-of-liaison-as-a-morpheme-specific-phonological-phenomenon-within-optimality-theory" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="learnability-of-liaison-as-a-morpheme-specific-phonological-phenomenon-within-optimality-theory"><span class="header-section-number">2.4</span> Learnability of liaison as a morpheme-specific phonological phenomenon within Optimality Theory</h2>
<p>The logical problem of language acquisition as summarized by Kager (2004: 323) from the original work on learnability in Optimality theory (Tesar and Smolensky, 2000) concerns learning three factors as shown in Figure 2-1: a. output representations; b. underlying representations; c.&nbsp;constraint hierarchy. These factors are assumed to be interdependent which means that learners in principle use iterative strategies to be able to go back and forth between these elements.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/fig2-1.png" class="img-fluid figure-img" width="800"></p>
<figcaption>Figure 2‑1. Interdependence of the three factors of output, underlying representation and constraint hierarchy in language acquisition taken from Kager (2004:323)</figcaption>
</figure>
</div>
<p>Fundamentally, as Tesar and Smolensky (2000) introduced this problem, learning could be decomposed along some dimensions with processes that must interpret the hidden structure of the output (robust parser component) and compute the optimal structure for the underlying form (lexicon learner component) through the constraint hierarchy (grammar learner component). Morphophonemic learning in contrast to phonotactic learning involves an additional layer of morphological information, specifically when deriving underlying representation. Consequently, learning idiosyncratic patterns of allomorphy involves interaction between different parts of linguistic knowledge, namely, the lexicon and phonology. Two aspects of learning, in particular, are of interest in this thesis for an account that deals with the learnability problem of morpheme-specific alternations like liaison.</p>
<p>Firstly, as demonstrated by the data in section 2.2, the idiosyncratic nature of external allomorphy patterns like liaison can be attributed to their extended domain. Mascaró (2004) highlights the paradoxes in this type of allomorphy with some examples from English which he refers to as external allomorphy. In the case of French liaison, to begin with, classifying word1s under liaison (allomorphy) or non-liaison (non-allomorphy) classes is not predictable by surface phonological forms. A lexical solution enables the learner to solve the problem for similar cases of unpredictability, for instance, regular vs.&nbsp;irregular past tense verbs in English: <em>walk</em>/<em>walk</em>-ed, <em>talk</em>/<em>talk</em>-<em>ed</em> vs.&nbsp;<em>buy</em>/<em>bought</em>, <em>bring</em>/<em>brought</em>. In cases when some verbs do not take the regular allomorph (-<em>ed</em> suffix), the past tense suppletive allomorph is listed in the lexicon. Whereas in liaison, a similar lexical solution does not suffice; learners must be aware of a bigger domain that extends beyond the word1 and includes the adjacent right word. For any given word1, the learner needs to know when to apply the allomorphy by considering if the word2 is C/V-initial. In other words, the learners would not be able to simply list every word1 + word2 phrase in the lexicon as they might do with the English irregular past tense forms.</p>
<p>Even though the classification of each word1 under allomorphy or non-allomorphy could seem rather arbitrary to the leaner and without any phonological motivations, phonological optimization is important for the participating word1s in liaison that do have an allomorphic pair. Predicting the choice of the allomorph in liaison patterns is possible through the lens of phonological optimization as it is natural to create forms that are following the most unmarked outcome in terms of syllable structure. However, if phonology is emerging to create an optimal structure in the larger prosodic domain of the allomorphy, the puzzle remaining for the learner is now the following question: why is it only restricted to just a limited set of lexical items? Simply stated, in the current case study, the lexical and arbitrary nature of allomorphy itself creates an arbitrary partition in the phonological grammar as shown in Figure 2-2. On the one side of the grammar, in the closed lexical set of liaison morphemes, prioritizing optimal structures in the grammar with constraints on markedness is required. While on the other side, in morphemes outside that closed lexical set, it is not.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/fig2-2.png" class="img-fluid figure-img" width="800"></p>
<figcaption>Figure 2.‑2. Partition in the phonological grammar for word1s in liaison or non-liaison classes</figcaption>
</figure>
</div>
<p>In the learning theory outlined below in the following subsections, I aim to address how this issue could be managed within the learner’s grammar. The current proposal involves a mechanism based on constraint indexation (Pater, 2010) applied to the learning of liaison.</p>
<p>The second rather unique property of liaison pertains to the locus of the alternation in the allomorphs along with the order of the of specific morphemes relative to each other. As seen in examples (1‒4) in Section 2.2. liaison is an external sandhi phenomenon which occurs in a domain of two morphemes where the first morpheme exhibits alternation on its right edge (e.g., [peti]~[petit]), bordering the left edge of the second morpheme. When the second morpheme begins with a vowel, the liaison consonant is resyllabified as an onset of the second morpheme. Therefore, especially in noun phrases where the second morpheme is a vowel-initial noun, the noun can be resyllabified with different onsets every time it is combined with a variety of liaison consonants in different contexts. Similar patterns are found in Celtic languages, which exhibit initial consonant mutation on their nouns in different contexts such as with pronouns or prepositions (Hannahs, 2011). However, such patterns are relatively uncommon and less widespread typologically compared to other cases of external allomorphy, where suffixation is more prevalent. As observed in the developmental trajectory of learning liaison, this presents challenges in the initial stages of learning morpho-phonological phenomena for learners, making it particularly challenging to correctly represent the input forms of morphemes involved in liaison.</p>
<p>In the following subsection, a detailed discussion of the issue regarding the input and its crucial role in a learnability account with an OT-based learning algorithm is presented. This is followed by an illustration of the formal properties that such a grammar must possess to enable learning.</p>
<section id="learning-the-underlying-representation" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="learning-the-underlying-representation"><span class="header-section-number">2.4.1</span> Learning the underlying representation</h3>
<p>In the course of acquisition, a learner must simultaneously learn the ranking and the lexicon. The latter has been incorporated into the system as identity mapping based on the principle of lexicon optimization (Prince and Tesar, 2004). When learners are faced with no evidence of overt alternations, the chosen underlying form among possible input forms is the one that makes the most faithful input-output mapping. Learning the underlying representations of morphemes is crucial to the process of learning the allomorphy, as “the underlying representations influence the grammar and the grammar influences the underlying representations” (McCarthy, 2005: 25). However, it is important to note that in a real-life scenario of language acquisition, morphological analysis and segmentation must be integrated with other aspects of learning. Leveraging the paradigmatic information in the alternation for computing the underlying representation seems accessible to the analyst. However, it is deemed to be tractable for learners only at a stage where they have made progress in understanding the semantics and segmentation of the phrases they encounter as overt forms.</p>
<p>In cases of allomorphy, the underlying representations of morphemes and the alternation are highly interdependent and “have to be inferred from combined analytic assumptions about the output and the constraint hierarchy” (Kager, 2004: 322). To expand on this, it is useful to first consider a less complex example of allomorphy as a point of comparison where the alternation is motivated by a phonotactic constraint in the language<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. In the previously mentioned example of the English past tense allomorphs (e.g., <em>walk</em>[t], <em>jog</em>[d], etc.), the conditions for the voicing alternations are true such that the suffix’s alveolar consonant is voiced after a voiced consonant and voiceless after a voiceless consonant. This distributional restriction also occurs within clusters in mono-morphemic words which are always similar in voicing. Having successfully learned the phonotactic constraints rankings governing the distributions of phonemes, in early stages of morphophonemic learning the learner needs to recognize the past tense morpheme as a suffix which means an underlying representation must be specified. Failing to select the appropriate underlying representation could result in the learner’s inability to learn the alternation given its existing constraint ranking. Theoretically, in the process of learning, when the learner makes errors on an alternation, two possible scenarios exist: either the constraint ranking within the grammar or the underlying representation would need to be revised. For the learners of the regular past tense allomorphy in English, modifying the grammar implies revising the constraint hierarchy which had been successful for mono-morphemic words. Any other constraint hierarchy would not be consistent with the rest of the learning data in English as a modified ranking could not apply to both the mono-morphemic words and words including the past tense suffix. Therefore, out of the two choices, the underlying representation is more likely to be revised. For learners of French, however, part of the challenge lies in the fact that liaison is not motivated by a phonotactic generalization that is language-wide. Furthermore, if the learner is to revise its underlying representations, as mentioned before, the unique location of the alternation in French liaison presents an additional layer of complexity for segmentation, which complicates the learning process of deriving underlying representation.</p>
<p>The information provided in the examples below can be categorized into two types: morphemic contrast and morphemic alternation (Tesar, 2014: 247). The following paradigm in (8) provides an opportunity for the learners to utilize the morphemic alternation information and compare phrases demonstrating diverse contexts for the same morpheme (in this case, plural determiner /le(z)/).</p>
<table class="table">
<colgroup>
<col style="width: 23%">
<col style="width: 24%">
<col style="width: 26%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">(8)</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">a.</td>
<td><em><strong>les</strong> bébés</em></td>
<td>[le.be.be]</td>
<td>‘the babies’</td>
</tr>
<tr class="even">
<td style="text-align: left;">b.</td>
<td><em><strong>les</strong> amis</em></td>
<td>[le.<strong>z</strong>a.mi]</td>
<td>‘the friends’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">c.</td>
<td><em><strong>les</strong> ours</em></td>
<td>[le.<strong>z</strong>u.ʁs]</td>
<td>‘the bears’</td>
</tr>
</tbody>
</table>
<p>To recognize the variation in the forms and to determine that both [le] and [lez] are two possible outputs for the same morpheme indicating the plural determiner, learners need to rely on their understanding of the underlying forms of the morphemes /bebe/ and /uʁs/ or /ami/. However, if the learner has not fully computed the underlying forms in the morphemic contrast paradigm for both the vowel-initial nouns (e.g., /uʁs/) and the consonant-initial nouns (e.g., /bebe/), their ability to learn the multiple representations for the allomorphy will be impacted. The issue specifically arises with vowel-initial nouns and their position. In the following contrastive paradigm in (9), the learners observe the noun /uʁs/ preceded by different morphemes.</p>
<table class="table">
<colgroup>
<col style="width: 21%">
<col style="width: 25%">
<col style="width: 28%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">(9)</th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">a.</td>
<td><em>les <strong>ours</strong></em></td>
<td>[le.<strong>z</strong>uʁs]</td>
<td>‘the bears’</td>
</tr>
<tr class="even">
<td style="text-align: left;">b.</td>
<td><em>un <strong>ours</strong></em></td>
<td>[œ̃.<strong>n</strong>uʁs]</td>
<td>‘a bear’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">c.</td>
<td><em>petit <strong>ours</strong></em></td>
<td>[pə.ti.<strong>t</strong>uʁs]</td>
<td>‘little bear’</td>
</tr>
<tr class="even">
<td style="text-align: left;">d.</td>
<td><em>joli <strong>ours</strong></em></td>
<td>[ʒɔ.li.uʁs]</td>
<td>‘nice bear’</td>
</tr>
</tbody>
</table>
<p>In this paradigm, the left edge of this noun in French is occupied by various liaison consonants (9a−c), except when it is adjacent to a non-liaison word1, as in (9d) with [ʒɔli]. This ordering results in an unstable position for the onset of the second word which has the potential to be rebracketed by the learners, as discussed in section 2.3. Understanding that these nouns do not have several C-initial variants and are in fact V-initial requires resisting the segmentation that aligns the onset of the nouns with the onset of the syllable. In phonological theories, aligning the onset of syllables and morphemes is part of the general alignment framework in the universal markedness constraints (McCarthy and Prince, 1993; Tesar and Smolensky, 2000). Consequently, particularly in early acquisition, it might not be surprising that this position of alternation contributes to how this issue is intuitively challenging to overcome. Furthermore, the role and saliency of onsets is also supported by various other psycholinguistic models of lexical segmentation such as the Syllable Onset Segmentation Hypothesis (Content et al., 2000), Shortlist B (Noris and McQueen, 2008).In the context of French liaison, the majority of word2s belong to an open class of lexical items (non-functional). Therefore, the need to resist alternations at the left edge of the word2s is crucial for the learning of the lexicon. As noted by Babineau et al.&nbsp;(2023: 305), “French liaison violates this universal constraint, as liaison sacrifices to some degree the number of minimal pair words in the lexicon”. This also has direct implications for the task of morphological parsing and learning the underlying representations. For example, English learners can infer, due to this bias, that a set of minimally different words like <em>foul, cowl, howl</em> are separate words and not just variants of a vowel-initial word like <em>owl</em>. Conversely, for French learners, syllables like [zuʁs], [tuʁs], [nuʁs] are not separate words, but rather all share the same vowel-initial word [uʁs]. Babineau et al.&nbsp;(2023) also note that this issue is not particularly severe, as the number of possible liaison consonants that can lead to ambiguous syllabification in French is limited to a few consonants.</p>
<p>By examining the issues surrounding underlying representations and segmentation, I have illustrated that learners must navigate the tension between language-specific properties and universal constraints in order to progress along the correct path. In the following subsection, I will propose a heuristic that could lead to a bias under which learning the underlying representations can be achieved for successful learning, and delve into the components of the initial state grammar along with the trajectory to the end state grammar.</p>
</section>
<section id="initial-state-grammar-to-end-state-grammar" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="initial-state-grammar-to-end-state-grammar"><span class="header-section-number">2.4.2</span> Initial state grammar to end state grammar</h3>
<p>In the initial state of the grammar, markedness constraints fully outrank faithfulness constraints. This initial state is adopted as it is well-supported by the evidence in the literature of phonological acquisition in Optimality Theory. Smolensky (1996a; 1996b) and Gnanadesikan (1995) suggest this initial state can account for both children’s production and comprehension. It also makes better predictions for learning with no positive evidence of alternations per the Subset Problem (Smolensky, 1996a, Prince and Tesar, 2004). This assumption is also connected to the richness of the base principle in Optimality theory where any imaginable input may be considered since the outputs are constrained by the interaction of constraints. Davidson et al.&nbsp;(2004) report results from experiments on the processing of infants and adults showing that this principle and its consequences for the initial ranking are supported by human linguistic performance. Apart from this traditional assumption, other possibilities within the literature include an unranked state or faithfulness constraints outranking markedness (Hale and Reiss, 1997).</p>
<p>In this analysis, I propose an initial state where all the learners of French start with the schematic Markedness &gt;&gt; Faithfulness constraint ranking with the constraints introduced below in (10).</p>
<p>(10) The initial state grammar G0:</p>
<p>a. Markedness constraints: all speakers have structural constraints for the most unmarked syllable structure (CV.CV): NoV.V<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, NoC.C<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> as well as alignment constraints Align-L<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p>b. Faithfulness constraints: all speakers have constraints that control the input-output correspondence (i.e., penalizing deletion and insertion of segments): Max<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, Dep<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p>c. These classes of constraints are ranked such that markedness constraints dominate the faithfulness constraint (M &gt;&gt; F):</p>
<p>NoV.V, NoC.C, Align-L &gt;&gt; Max, Dep</p>
<p>In order to tackle the questions of learning morpho-phonological patterns, I focus on basic examples of prenominal configurations introduced above in section 2.2, such as the&nbsp;common sequence of the plural determiner [le]/[lez] + nouns. Beginning from a universal initial state typical of learners of all languages, how does the grammar of learners of French develop as they are exposed to French-specific phonological patterns until they have fully learned morpheme-specific phonological alternations like liaison? The analysis provided here incorporates a mechanism that enables learners to recognize and address inconsistencies in their grammar adopting Pater (2010). This analysis is also informed by additional biases in two places, which will be elaborated upon later throughout this subsection. The learning algorithm implemented in the current analysis follows the <em>biased error-driven constraint demotion</em> algorithm (Prince and Tesar, 2004; Hayes, 2004). Implementing this algorithm, not only does the learner start with a markedness bias in its initial state, but it is also biased towards the markedness constraints during reranking stages or constraint demotion.</p>
<p>In the early stages of phonological development, as discussed in section 2.3, children learn language-specific phonotactics. For my analysis, I assume that prior to learning morphology, French learners acquire some phonotactic and distributional information about their language, which informs their language-specific knowledge. This suggests that during this early stage of learning, out of a tendency to maximize lexicon optimization, the initial bias of highly ranked universal constraints favouring unmarked structures would be gradually overridden by the set of constraints related to being faithful to the input form of words. In the error-driven process of learning, among the sets of phrases that contribute to learners’ language-specific phonotactic knowledge is the non-alternating adjective + nouns in our examples. The non-alternating class of morphemes in general involves an open class of lexical items, making them shape most of the lexicon as they are more frequent type-wise. A learner who encounters phrases such as <em>jeune</em> <em>bébé</em> and <em>joli ami</em> as well as many other similar verbal or prepositional phrases (containing V.V and C.C syllable patterns) simply stores each new word they learn in the input as is, based on the principles of lexicon optimization. The relevant errors learners make with regard to these phrases lead them to updating the initial state constraint ranking. During the update, the biased constraint demotion algorithm imposes a bias in favour of markedness constraints, therefore they are not to be demoted as long as possible</p>
<p>To illustrate how an ideal learning trajectory progresses at each step with an error-driven algorithm, first a table of error archives is presented, and then after resolving the errors, some example tableaux are provided with the new updated grammar at each stage. The table below shows the error archive and provides a pair of candidates consisting of the winning candidate (the observed output) and one losing candidate selected by the current grammar for each input. Each row in this error archive, which is known as the error, indicates whether the constraints prefer the optimal winner (W) or the&nbsp;suboptimal competitor, the loser (L). The novelty in my analysis is the first column in the table called “Error by Current Grammar” which notes whether the errors present in the error archive were made by the current state of the grammar. The current grammar of the learners, written on top of the table, has led them to the errors marked by √. Importantly, the concept of an error archive refers to a kind of permanent storage accessible to the algorithm where learners record their errors. If at any point during learning, the algorithm reads the archive and an error lacks any marks in the first column, it means that it has been archived in previous stages. At the same time, the inputs of input-output mappings that do not make it into the error archive are stored directly in the lexicon also accessible in phonological learning. At this point, the current grammar is the initial state grammar stated in (10).</p>
<p>(11) Error archive with errors of the CG (<span class="smallcaps">NoV.V, NoC.C, Align-L &gt;&gt; Max, Dep</span>)</p>
<table class="table">
<colgroup>
<col style="width: 8%">
<col style="width: 10%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Error by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">Dep</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">a. /ʒɔli+ami/</td>
<td style="text-align: left;">ʒɔli.ami ~ ʒɔli.zami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;">b. /ʒɔli+ami/</td>
<td style="text-align: left;">ʒɔli.ami ~ ʒɔ.lami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">c. /ʒœn+bebe/</td>
<td style="text-align: left;">ʒœn.bebe ~ ʒœ.bebe</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;">d. /ʒœn+bebe/</td>
<td style="text-align: left;">ʒœn.bebe ~ ʒœni.bebe</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
</tr>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">e. /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.nami ~ ʒœ.ami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>As can be seen from the errors above, the very initial state grammar leads the learner to select these losing candidates which have unmarked syllable structures. Once new errors enter the error archive marked by √, the error-driven algorithm then requires an update and initiates a new constraint hierarchy according to the violation profiles of each candidate pair in terms of their constraint preference. With the biased constraint demotion algorithm, markedness constraints have priority to be placed at the top of the new stratum of the constraint hierarchy provided they prefer no losers. However, this is not the case at this stage, as there are not any markedness constraints which would prefer no losers. Whereas faithfulness constraints, Max and Dep, prefer the winning candidates of the pairs in each error. It is worthwhile to note that including errors that result in reranking Align-L in the first error archive, as seen in cases like error (11e) serves the purpose of providing a comprehensive analysis of all constraints. However, realistically, during the initial stages of phonotactic acquisition, learners may not be fully aware of morphological boundaries within phrases<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>. In this update, the resulting crucial constraint ranking in (12), achieved by the learner during the phonotactic learning stage, ensures that such errors are not being made anymore moving forward. Thus, all the errors in (11a-e) are then successfully archived.</p>
<p>(12) Phonotactic Grammar: <span class="smallcaps">Dep, Max &gt;&gt; NoV.V, NoC.C, Align-L</span></p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒœn/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">Dep</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[ʒœn.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">[ʒœ.ni.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td></td>
<td style="text-align: left;">[ʒœ.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 10%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒœn/+/ami/</th>
<th style="text-align: left;"><span class="smallcaps">Dep</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[ʒœ.na.mi]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">[ʒœ.a.mi]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒɔli/ +/ami/</th>
<th style="text-align: left;"><span class="smallcaps">Dep</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[ʒɔ.li.a.mi]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">[ʒɔ.li.za.mi]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
<tr class="odd">
<td></td>
<td style="text-align: left;">[ʒɔ.la.mi]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<p>The important argument made here for the grammar in (12) is based on a reasonable assumption that when learners arrive at the inconsistency between liaison and non-liaison morphemes, they already possess a not-so-naïve grammar. The grammar with which they enter morphophonemic learning is not exactly the same as the initial state grammar and has undergone some modifications. This is illustrated in the tableaux above and evidenced by an error archive that accumulates as they encounter simple phrases during phonotactic learning.</p>
<p>Gradually, learning the underlying representations of the alternating morphemes becomes more feasible for the learner after gaining some knowledge about the phonotactics and the lexicon. When learners develop a certain level of awareness regarding morphological parsing through semantic or visual cues in the real world, they start forming hypotheses about the additional morpheme they have identified before the nouns in determiner + noun phrases. In other words, the learner eventually must realize that the phrases <em>les amis</em> and <em>les bébés</em> are not monomorphemic and contain more than one morpheme. At the same time, they could conclude that the first morphemes of these phrases are, in fact, semantically related and function as determiners. Incidentally, one type of evidence that can aid them in learning the underlying representation of the alternating liaison morphemes could come from the knowledge of nouns’ underlying representations, especially when learners compare different contrastive paradigms in (9). For instance, as learners become more proficient in understanding the representations of the nouns, they may find it more likely that among the forms they had encountered for the noun ‘friend’ (e.g., [tami], [zami] and [ami]), the underlying representation is /ami/ rather than the other C-initial forms. This realization could in fact lead them to segment the phrases correctly and discover that the first morphemes in phrases like /lez+ami/ or /le+bebe/ are not only semantically related, but are actually the same morpheme. By exploring different options for the underlying representations of the determiner, learners can formulate a range of hypotheses. First, I propose that learners prefer to maintain a single underlying representation rather than positing multiple ones. This approach narrows the hypotheses window and it simplifies the learning process by shifting the responsibility of learning onto the grammar, rather than requiring extensive storage in the lexicon. In this scenario, learners would be faced with two possibilities and they must select one as the underlying form: either the input is shaped as CVC or CV. The two tables below are provided just to illustrate the comparison between the larger input in CVC form (13a-d), and the smaller input in CV form (13e-h). If the learner takes the hypothesis of larger allomorph as the input such as /lez/ or /œ̃n/, the resulting errors would have the following preferences where Dep is indifferent with respect to winners or losers.</p>
<p>(13)</p>
<table class="table">
<colgroup>
<col style="width: 4%">
<col style="width: 10%">
<col style="width: 15%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td>Input</td>
<td>W ~ L</td>
<td><span class="smallcaps">NoC.C</span></td>
<td><span class="smallcaps">NoV.V</span></td>
<td><span class="smallcaps">Align-L</span></td>
<td><span class="smallcaps">Max</span></td>
<td><span class="smallcaps">Dep</span></td>
</tr>
<tr class="even">
<td>a.</td>
<td>/lez/ + …</td>
<td><strong>le.z</strong>ami ~ le.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td>W</td>
<td></td>
</tr>
<tr class="odd">
<td>b.</td>
<td>/lez/ + …</td>
<td>le.bebe ~ <strong>lez</strong>.bebe</td>
<td>W</td>
<td></td>
<td></td>
<td>L</td>
<td></td>
</tr>
<tr class="even">
<td>c.</td>
<td>/œ̃n<strong>/</strong> + …</td>
<td><strong>œ̃.n</strong>ami ~ œ̃.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td>W</td>
<td></td>
</tr>
<tr class="odd">
<td>d.</td>
<td>/œ̃n<strong>/</strong> + …</td>
<td>œ̃.bebe ~ <strong>œ̃n</strong>.bebe</td>
<td>W</td>
<td></td>
<td></td>
<td>L</td>
<td></td>
</tr>
</tbody>
</table>
<p>If the learner takes the hypothesis of the smaller allomorph as the input such as /le/ or /œ̃/, the resulting errors would have different preferences where Max is indifferent with respect to winners or losers.</p>
<p>(13)</p>
<table class="table">
<colgroup>
<col style="width: 4%">
<col style="width: 7%">
<col style="width: 17%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td>Input</td>
<td>W ~ L</td>
<td><span class="smallcaps">NoC.C</span></td>
<td><span class="smallcaps">NoV.V</span></td>
<td><span class="smallcaps">Align-L</span></td>
<td><span class="smallcaps">Max</span></td>
<td><span class="smallcaps">Dep</span></td>
</tr>
<tr class="even">
<td>e.</td>
<td>/le/ + …</td>
<td><strong>le</strong>.bebe ~ lez.bebe</td>
<td>W</td>
<td></td>
<td></td>
<td></td>
<td>W</td>
</tr>
<tr class="odd">
<td>f.</td>
<td></td>
<td>le.<strong>z</strong>ami ~ <strong>le</strong>.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td></td>
<td>L</td>
</tr>
<tr class="even">
<td>g.</td>
<td>/œ̃/ + …</td>
<td><strong>œ̃</strong>.bebe ~ œ̃n.bebe</td>
<td>W</td>
<td></td>
<td></td>
<td></td>
<td>W</td>
</tr>
<tr class="odd">
<td>h.</td>
<td></td>
<td>œ̃.<strong>n</strong>ami ~ <strong>œ̃</strong>.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td></td>
<td>L</td>
</tr>
</tbody>
</table>
<p>My proposed heuristic could be in form of a bias in favour of storing the unpredictable information in the input by maximizing the structure encoded in the input. Under this heuristic, the larger allomorph /lez/ or /œ̃n/ (13a-d) would be the best underlying representation among the possible input forms. In other words, in instances of determiner + V-initial noun combinations when the learner has the opportunity to encounter the allomorph form with a maximal structure (here the CVC form), that should be the preferred choice<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. With this input the grammar relies on satisfying the <span class="smallcaps">NoC.C</span> constraint at the expense of <span class="smallcaps">Max</span>, that is, not being faithful to the input by deleting the final consonant<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>. Other existing alternative analyses in the literature regarding French liaison in an OT-based grammar employ other mechanisms such as constraints for the UR (Smith, 2015) or multiple URs (Storme, 2024). However, applying this simple heuristic renders the input in conjunction with the ranking in the grammar learnable. As a result of choosing the larger allomorph for the underlying representation, learners are left with errors with the error proflies exemplified below in (14). Note that the other faithfulness constraint <span class="smallcaps">Dep</span> is not playing a role among the crucial constraints anymore.</p>
<p>(14)</p>
<table class="table">
<colgroup>
<col style="width: 4%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">DEP</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>a.</td>
<td style="text-align: left;">/lez<strong>+</strong>ami/</td>
<td style="text-align: left;">le.zami ~ le.ami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>b.</td>
<td style="text-align: left;">/lez<strong>+</strong>bebe/</td>
<td style="text-align: left;">le.bebe ~ lez.bebe</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>To continue learning and to achieve a stable end-state of the grammar, the learner must reconcile the morpheme-specific constraints in two conflicting rankings within its grammar. In my current learnability analysis, I incorporate a mechanism borrowed from Pater’s (2010) constraint indexation model of Optimality Theory to analyze morpheme-specific phonology and exceptionality. He argues that this approach to morpheme-specific phonology offers advantages over previous proposals such as co-phonologies by Inkelas and Zoll (2007). Although similar mechanisms of indexation have been previously proposed by Fukuzawa (1999) and Ito and Mester (2001) for faithfulness constraints, Pater’s (2010) version allows both markedness constraints and faithfulness constraints to be lexically indexed if necessary. According to this approach, inconsistencies can be identified and resolved as the learner encounters them through facing errors during the learning process. The error archive below demonstrates a winner-loser pair for each input, representing the two classes of morphemes. The inconsistency is evident in error rows bolded (15c vs 15d) as there is not a consistent constraint that prefers only Ws. Here each constraint favours a morpheme belonging to a different class and the&nbsp;reranking algorithm reaches a halt. The current grammar of the learners making the last two errors (15d-e) marked below with √ is the grammar after phonotactic learning in (12). The other rows (15a-c) are the previous errors stored in the error archive<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>.</p>
<p>(15) Error archive with errors of the CG (<span class="smallcaps">Max &gt;&gt; NoV.V, NoC.C, Align-L</span>)</p>
<table class="table">
<colgroup>
<col style="width: 8%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Error by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">a. NL W1: /ʒɔli+ami/</td>
<td style="text-align: left;">ʒɔliami ~ ʒɔlami</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">b. NL W1: /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.na.mi ~ ʒœ.ami</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>c.&nbsp;NL W1: /ʒœn+bebe/</strong></td>
<td style="text-align: left;"><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td style="text-align: left;"><strong>W</strong></td>
<td style="text-align: left;"><strong>L</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;"><strong>d.&nbsp;L W1s: /lez+bebe/</strong></td>
<td style="text-align: left;"><strong>le.bebe ~ lez.bebe</strong></td>
<td style="text-align: left;"><strong>L</strong></td>
<td style="text-align: left;"><strong>W</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">e. L W1s: /lez+ami/</td>
<td style="text-align: left;">le.za.mi ~ le.ami</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
</tr>
</tbody>
</table>
<p>Following the instructions in the algorithm under Pater’s (2010: 20, ex 48) account for inconsistency resolution, the learner must perform the instruction given in (16).</p>
<p>(16) Clone a constraint that prefers only Ws in all instances of some morpheme, and index it to every morpheme for which it prefers only Ws.</p>
<p>As Pater notes in his work, an aspect of constraint cloning remains to be fully elaborated. Particularly, how does the learner proceed when the choice of the constraint to be cloned is not straightforwardly down to one single constraint? The appendix in the original work by Pater (2010) reviews procedures that could be performed by the algorithm (borrowed from linear programming) during learning when the algorithm can not decide which constraint to clone to resolve the inconsistency. He also discusses one option to be the inclusion of an “exceptional” bias targeting the smallest set of morphemes to help the learner choose one solution over the other depending on the lexicon, but he concludes that this procedure needs further research.</p>
<p>My analysis includes the proposal of a bias which could enable the learner to decide among equally available options for constraint cloning. This bias is shaped by considering the current grammar which is itself driven by earlier errors in the error archive. An explicit adjustment to the previous statement is stated in (17).</p>
<p>(17) Clone the constraint that prefers Ws in all instances of the errors committed by the <strong>current grammar</strong> and index it to morphemes for which it prefers only Ws for those errors.</p>
<p>The minimal inconsistent pairs of errors for French learners /lez+bebe/ and /ʒœn+bebe/ are shown again in a new table below in (18).</p>
<p>(18) Minimal inconsistent pairs of errors by the CG (<span class="smallcaps">Max &gt;&gt; NoV.V, NoC.C, Align-L</span>)</p>
<table class="table">
<colgroup>
<col style="width: 8%">
<col style="width: 15%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Error by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>NL W1: /ʒœn+bebe/</strong></td>
<td style="text-align: left;"><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td style="text-align: left;"><strong>W</strong></td>
<td style="text-align: left;"><strong>L</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;"><strong>L W1s: /lez+bebe/</strong></td>
<td style="text-align: left;"><strong>le.bebe ~ lez.bebe</strong></td>
<td style="text-align: left;"><strong>L</strong></td>
<td style="text-align: left;"><strong>W</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>At this juncture, the choice of cloning the winning preferring constraint is not apparent. The two options below are both equally available to the learner to resolve the inconsistency:</p>
<ol type="a">
<li><p>Clone No C.C indexed to liaison W1s (e.g., /lez/)</p></li>
<li><p>Clone Max indexed to non-liaison W1s (e.g., /ʒœn/)</p></li>
</ol>
<p>As mentioned before, the important assumption taken for granted is that learners of French have a different (more mature) grammar from the initial state grammar at the point when they reach this inconsistency. As can be seen from the winner~loser pair above, currently, non-liaison word1s do not lead to an error by the learner anymore as the W preferring constraint for them is <span class="smallcaps">Max</span> which is highly-ranked in the current grammar. A word1 in the liaison class (L W1) is the recent error made by the current grammar. Therefore, guided by the bias introduced in (17) they must clone the constraint preferring Ws for the liaison word1 morpheme (<span class="smallcaps">NoC.C</span>), as it is the error committed by the current grammar and index it to that morpheme (<span class="smallcaps">NoC.C-L</span>). The clone constraint is added to the constraint hierarchy as shown in (19).</p>
<p>(19)</p>
<table class="table">
<colgroup>
<col style="width: 7%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Error by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">No C.C-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">No C.C</span></th>
<th style="text-align: left;"><span class="smallcaps">No V.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">a. NLW1: /ʒɔli+ami/</td>
<td style="text-align: left;">ʒɔliami ~ ʒɔlami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">b. NLW1: /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.na.mi ~ ʒœ.ami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>c.&nbsp;NLW1: /ʒœn+bebe/</strong></td>
<td style="text-align: left;"><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;"><strong>d.&nbsp;LW1s: /lez+bebe/</strong></td>
<td style="text-align: left;"><strong>le.bebe ~ lez.bebe</strong></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">e. LW1s: /lez+ami/</td>
<td style="text-align: left;">le.za.mi ~ le.ami</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
</tr>
</tbody>
</table>
<p>Now with the new cloned constraint present, the reranking procedure in the update can be restarted. I will illustrate the biased constraint demotion algorithm here step-by-step. Among markedness constraints, the <span class="smallcaps">NoC.C-L</span> constraint is placed on the top stratum, shown in (20), as it is the only markedness constraint that prefers only Ws in an instance of some morpheme. After this constraint is placed at the top of the hierarchy the relevant errors in rows (d-e) would technically be resolved and successfully archived.</p>
<p>(20) No C.C-L &gt;&gt;</p>
<table class="table">
<colgroup>
<col style="width: 7%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 12%">
<col style="width: 10%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Error by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">No C.C-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">No C.C</span></th>
<th style="text-align: left;"><span class="smallcaps">No V.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">a. NLW1: /ʒɔli+ami/</td>
<td style="text-align: left;">ʒɔliami ~ ʒɔlami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">b. NLW1: /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.na.mi ~ ʒœ.ami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>c.&nbsp;NLW1: /ʒœn+bebe/</strong></td>
<td style="text-align: left;"><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"><del>√</del></td>
<td style="text-align: left;"><del><strong>d.&nbsp;LW1s: /lez+bebe/</strong></del></td>
<td style="text-align: left;"><del><strong>le.bebe ~ lez.bebe</strong></del></td>
<td style="text-align: left;"><del>W</del></td>
<td style="text-align: left;"><del>L</del></td>
<td style="text-align: left;"><del>W</del></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><del>√</del></td>
<td style="text-align: left;"><del>e. LW1s: /lez+ami/</del></td>
<td style="text-align: left;"><del>le.za.mi ~ le.ami</del></td>
<td style="text-align: left;"><del>W</del></td>
<td style="text-align: left;"><del>W</del></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><del>W</del></td>
<td style="text-align: left;"><del>L</del></td>
</tr>
</tbody>
</table>
<p>As the inconsistency is now resolved, the update can proceed with a similar procedure as before based on the winner~loser pairs in (20a-c). No markedness constraint prefers only Ws, therefore the faithfulness constraint is the next constraint to be placed in the new stratum. At the end, the learner has the hierarchy shown in (21) with a cloned constraint indexed to the set of morpheme(s) with the same index (here L chosen to stand for liaison morphemes).</p>
<p>(21)</p>
<p>No C.C-L &gt;&gt; Max &gt;&gt; No C.C, No V.V, Align-L *L: {/lez/, …}</p>
<p>The two tableaux below (22) show examples of phrases attached to an&nbsp;indexed subset of the lexicon [lebebe] and [lezami]. Notice that the underlying representation of the word1 is the consonant-final form /lez/ which means NoC.C-L<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> has to crucially outrank Max and Max has to in turn crucially outrank Align-L.</p>
<p>(22)</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 12%">
<col style="width: 17%">
<col style="width: 13%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/lez/<sub>L</sub>+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">No C.C-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">No C.C</span></th>
<th style="text-align: left;"><span class="smallcaps">No V.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[le.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">[lez.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 11%">
<col style="width: 17%">
<col style="width: 13%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/lez/<sub>L</sub>+/ami/</th>
<th style="text-align: left;"><span class="smallcaps">No C.C-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">No C.C</span></th>
<th style="text-align: left;"><span class="smallcaps">No V.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[le.za.mi]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">[le.ami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>It is also worth illustrating in (23) that this new cloned constraint does not affect words like [ʒœnbebe] or [ʒɔliami] because it is only indexed to certain word1s (liaison word1s).</p>
<p>(23)</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 19%">
<col style="width: 13%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒœn/+/bebe/</th>
<th style="text-align: left;">NoC.C-L</th>
<th style="text-align: left;">Max</th>
<th style="text-align: left;">NoC.C</th>
<th style="text-align: left;">NoV.V</th>
<th style="text-align: left;">Align-l</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[ʒœn.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">[ʒœ.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 21%">
<col style="width: 12%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒɔli/+/ami/</th>
<th style="text-align: left;">NoC.C-L</th>
<th style="text-align: left;">Max</th>
<th style="text-align: left;">NoC.C</th>
<th style="text-align: left;">NoV.V</th>
<th style="text-align: left;">Align-l</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[ʒɔ.li.a.mi]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: left;">[ʒɔ.la.mi]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>A crucial concluding step remains in this analysis. The process outlined above addresses the procedure for instances of a single morpheme. Although multiple liaison morphemes in French need to be indexed, they constitute a finite set. Therefore, whenever learners encounter phrases containing new morphemes that fall within the same class as liaison words, such as the masculine singular indefinite article + noun in <em>un ami</em>, the same procedure applies to resolve any inconsistencies. In this case, the cloned constraints for each morpheme would essentially be duplicates of the NoC.C constraint and positioned within the same top stratum (24).</p>
<p>(24)</p>
<p><span class="smallcaps">No C.C-L2**, No C.C-L* &gt;&gt; Max &gt;&gt; No C.C, No V.V, Align-L</span> *L: {/lez/} **L2: {/œ̃n/}</p>
<p>Therefore, we expect that learners may have the option to either merge or delete the extra constraints, ultimately retaining a single constraint linked to multiple indexed liaison words instead. The complete final grammar in the current analysis where learners would converge on an end state, including all the relevant constraints, therefore would be as in (25).</p>
<p>(25) Final state grammar:</p>
<p><span class="smallcaps">No C.C -L* &gt;&gt; Max &gt;&gt; No C.C, No V.V, Align-L</span> *L: {/lez/, /œ̃n/, …}</p>
<p>It is beneficial at the end of this subsection to highlight that several key points emerge from this analysis based on certain underlying assumptions regarding an ideal learner. Firstly, it is assumed that the learners are equipped with a universal biased M&gt;&gt;F ranking in their initial state which leads to their first errors during phonotactic learning. Subsequently, another assumption posits that as a result of successful phonotactic learning, the ideal learner maintains a specific ranking of the grammar at the time of encountering inconsistencies and during the learning of allomorphy. This ideal trajectory shapes the bias that enables the learners to successfully overcome the challenge of learning morpheme-specific alternations in this analysis. As previously mentioned, other alternative biases for learning indexation in morpheme-specific patterns according to Pater (2010) include a bias for the smallest set of morphemes or constraints. In this regard, it remains ambiguous whether a definitive solution exists for assessing the relative frequency of liaison morphemes compared to non-liaison morphemes, as well as whether such criteria could be appropriately applied to these morphemes in a phonologically conditioned allomorphy domain. Therefore, an additional crucial criterion favouring the errors made by the current grammar was introduced and incorporated in this analysis.</p>
<p>In an earlier work on constraint indexation, Pater (2007:11) introduced the concept of constraint indexation in a context where the order of winner-loser pairs created by the learners is not explicitly addressed. He mentioned in a footnote that if a learner possesses an incomplete set of learning data, there is a risk of incorrectly cloning certain constraints. However, he then posits that this would likely have minimal impact, as these constraints would eventually be ranked lower in the hierarchy if they do not contribute to resolving inconsistencies. To further explore this idea with hypothetical learning processes, I have devised various experimental scenarios that control the sequence in which participants are exposed to different types of learning data. Additionally, I ensured that the experimental environment did not allow learners to exhibit exceptional biases based on familiarity with the lexicon or frequency. In the following section, I will review these conditions and discuss the predictions derived from them, enabling comparisons based on participants’ accuracy and errors.</p>
</section>
</section>
<section id="predictions-of-the-learning-theory-in-the-current-study" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="predictions-of-the-learning-theory-in-the-current-study"><span class="header-section-number">2.5</span> Predictions of the learning theory in the current study</h2>
<p>The current study aims to compare the learning of morpheme-specific phonological patterns across various controlled learning trajectories. The order in which learning data was presented to the participants was carefully controlled in an experimental setting designed to induce an inconsistency detection in the learner’s learning algorithm. Before expanding on my predictions regarding the different learning trajectories, it is important to establish the assumptions guiding the hypotheses. The most crucial assumption is that, in all learners in the experiment, the initial state aligns with the state described in section 2.4.2. This means that, rather than possessing a set of unranked constraints, learners exhibit strong biases toward the most unmarked syllable structure (CV.CV) (for related points about the methodology of artificial language learning experiment and to the extent where L1 biases are transferred, see Tang and Baer-Henney, 2023) .</p>
<p>Therefore, I assume that in an experimental setting, the initial state of all learners follows the G0 below in (26) with faithfulness constraints being outranked by markedness constraints.</p>
<p>(26)</p>
<p>G0: <span class="smallcaps">NoC.C, NoV.V, Align-L &gt;&gt; Max</span></p>
<p>Moreover, as per my analysis discussed above following Pater (2010), I assume that learners would update their grammar based on the learning evidence presented to them at any given point. This grammar operates within a single hierarchy of constraints, requiring learners to rerank their constraints and make updates when faced with new evidence of errors or of inconsistencies. In the experiment, I investigated three different learning trajectories, assuming all are starting from the same initial state grammar (26) but exposed to merely positive learning data. These trajectories involved receiving either both classes of morphemes at once or in an isolated manner, one by one. The learning data consisted of phrases in an artificial mini-language that included similar patterns to the morpheme-specific phonological patterns in French. This mini-language consists of four word1s (two liaison, and two non-liaison) along with several word2s and its presentation to participants in the experiment is divided into two blocks (for more details, refer to Chapter 3). In the next subsections, I draw upon real French phrases to demonstrate the three learning trajectories and examine the outcome predicted by my hypotheses.</p>
<section id="ordered-learning-trajectory---liaison-first" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="ordered-learning-trajectory---liaison-first"><span class="header-section-number">2.5.1</span> Ordered learning trajectory - Liaison first</h3>
<p>In this group of learners, the first block involves receiving two liaison morphemes while the second block includes the two non-liaison morphemes. In this manner, the initial evidence presented to learners based on what they encounter in the first block lacks any form of inconsistency.</p>
<p>In <strong>the first block</strong>, the ideal learner who has established the semantic connection between the allomorphs needs to identify the larger consonant-final allomorph /lez/ and /œ̃n/ as the underlying representation when presented with the following set of phrases: {le+bebe, lez+ami, …, œ̃+bebe, œ̃n+ami, …}. By the end of the first block, assuming an initial state bias from G0, the learner does not make any errors with [lebebe] or [œ̃bebe]. However, the learner is required to rerank its constraint hierarchy due to errors introduced by Align-L which only occur with phrases such as [lezami] and [œ̃nami]<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> shown in (27).</p>
<p>(27)</p>
<table class="table">
<colgroup>
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">a.</th>
<th style="text-align: left;">/lez/+/bebe/</th>
<th style="text-align: left;">NoC.C</th>
<th style="text-align: left;">NoV.V</th>
<th style="text-align: left;">Align-L</th>
<th style="text-align: left;">Max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">[lez.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">☞</td>
<td style="text-align: left;">[le.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 15%">
<col style="width: 19%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">b.</th>
<th style="text-align: left;">/lez/+/ami/</th>
<th style="text-align: left;">NoC.C</th>
<th style="text-align: left;">NoV.V</th>
<th style="text-align: left;">Align-L</th>
<th style="text-align: left;">Max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">☹</td>
<td style="text-align: left;">[le.zami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">☞</td>
<td style="text-align: left;">[le.ami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<p>At this stage, the input forms /lez/ and /bebe/ directly enter the lexicon of the learner as there are no errors made on them. However, the phrase leading to the error in (27b) are shown in table (28) below.</p>
<p>(28) Error archive with errors of the CG (NoC.C, NoV.V, Align-L &gt;&gt; Max)</p>
<table class="table">
<colgroup>
<col style="width: 10%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 16%">
<col style="width: 13%">
</colgroup>
<tbody>
<tr class="odd">
<td>Errors by CG</td>
<td>Input</td>
<td>W ~ L</td>
<td><span class="smallcaps">NoC.C</span></td>
<td><span class="smallcaps">NoV.V</span></td>
<td><span class="smallcaps">Align-L</span></td>
<td><span class="smallcaps">Max</span></td>
</tr>
<tr class="even">
<td>√</td>
<td>a. L W1: /lez+ami/</td>
<td>le.zami ~ le.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td>W</td>
</tr>
<tr class="odd">
<td>√</td>
<td>b. L W1: /œ̃n+ami/</td>
<td>œ̃.na.mi ~ œ̃.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td>W</td>
</tr>
</tbody>
</table>
<p>As the table in (28) shows, the two markedness constraints that prefer no losers are <span class="smallcaps">NoC.C</span> and <span class="smallcaps">NoV.V</span>. The biased constraint demotion would result in a crucial ranking among the markedness constraints, so they are no longer equally ranked in the top stratum of the hierarchy in (29). The two errors in (28a‒b) are archived successfully, as the learner proceeds.</p>
<p>(29)</p>
<p>Liaison G1: <span class="smallcaps">No C.C, No V.V &gt;&gt; Align-L &gt;&gt; Max</span></p>
<p>In <strong>the second block</strong> of learning, learners are presented with the non-liaison morphemes only: {ʒœn+bebe, ʒœn+ami, …, ʒɔli+ami, ʒɔli+bebe, …}, and they would make errors with these new word1s with their current grammar in G1 shown in tableaux below in (30).</p>
<p>(30)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒœn/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☹</td>
<td style="text-align: left;">[ʒœn.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>☞</td>
<td style="text-align: left;">[ʒœ.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒɔli/+/ami/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☹</td>
<td style="text-align: left;">[ʒɔli.ami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>☞</td>
<td style="text-align: left;">[ʒɔ.lami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<p>Due to the errors recorded in their error archive recently as exemplified in the table below in (31), they are required to rerank and update their highest-ranked constraints from G1. Errors (31a‒b) are previous errors from the first block stored in the error archive and errors (31c‒d) are errors made by the current grammar marked by √.</p>
<p>(31) Error archive with errors of the CG (<span class="smallcaps">No C.C, No V.V &gt;&gt; Align-L &gt;&gt; Max)</span></p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
<col style="width: 12%">
</colgroup>
<tbody>
<tr class="odd">
<td>Errors by CG</td>
<td>Input</td>
<td>W ~ L</td>
<td><span class="smallcaps">NoC.C</span></td>
<td><span class="smallcaps">NoV.V</span></td>
<td><span class="smallcaps">Align-L</span></td>
<td><span class="smallcaps">Max</span></td>
</tr>
<tr class="even">
<td></td>
<td>a. L W1: /lez+ami/</td>
<td>le.zami ~ le.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td>W</td>
</tr>
<tr class="odd">
<td></td>
<td>b. L W1: /œ̃n+ami/</td>
<td>œ̃.na.mi ~ œ̃.ami</td>
<td></td>
<td>W</td>
<td>L</td>
<td>W</td>
</tr>
<tr class="even">
<td>√</td>
<td>c. NL W1: /ʒœn+bebe/</td>
<td>ʒœn.bebe ~ ʒœ.bebe</td>
<td>L</td>
<td></td>
<td></td>
<td>W</td>
</tr>
<tr class="odd">
<td>√</td>
<td>d. NLW1: /ʒɔli+ami/</td>
<td>ʒɔli.ami ~ ʒɔ.lami</td>
<td></td>
<td>L</td>
<td>W</td>
<td>W</td>
</tr>
</tbody>
</table>
<p>As the table in (31) shows, no markedness constraint prefers only Ws, therefore the winner-preferring faithfulness constraint <span class="smallcaps">Max</span> is ranked first at the top stratum in (32) and the other constraints are basically demoted.</p>
<p>(32)</p>
<p>Liaison G2: Max &gt;&gt; No C.C, No V.V, Align-L</p>
<p>During the second block, the learners are only exposed to evidence of the non-liaison morphemes. However, the ideal learner not only has a complete archive of the errors, but they also have access to the lexicon they learned in this language up until this point. Even though they do not encounter them in this block, they must notice that the phrases in the second block differ significantly from the earlier phrases to eventually realize that the current G2 grammar will produce errors with /lez+bebe/ and other phrases with a similar structure (…VC.CV…) as demonstrated in a tableau in (33). Recall that these input to these phrases, previously shown in a tableau in (27a), had entered the lexicon directly with no issues in the first block.</p>
<p>(33)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/lez/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[lez.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>☹</td>
<td style="text-align: left;">[le.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Now powered by the G2, this recent error initiates an update to the grammar. As the learner compiles all evidence in the archive, they would realize the necessity of addressing the ranking paradox between the morphemes belonging to the two classes of word1s. The table below, which includes all the errors, illustrates the minimal inconsistent pair that highlights the inconsistency (34d vs 34e) in bold—where specific constraints (<span class="smallcaps">Max</span> and <span class="smallcaps">NoC.C</span>) exhibit the opposite preferences for the morphemes presented in the two blocks of the experiment. The learner is unable to continue the reranking process to install any constraints at this point.</p>
<p>(34) Error archive with errors of the CG (Max &gt;&gt; No C.C, No V.V, Align-L<span class="smallcaps">)</span></p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<tbody>
<tr class="odd">
<td>Errors by CG</td>
<td>Input</td>
<td>W ~ L</td>
<td><span class="smallcaps">Max</span></td>
<td><span class="smallcaps">No C.C</span></td>
<td><span class="smallcaps">No V.V</span></td>
<td><span class="smallcaps">Align-L</span></td>
</tr>
<tr class="even">
<td></td>
<td>a. LW1: /lez+ami/</td>
<td>le.zami ~ le.ami</td>
<td>W</td>
<td></td>
<td>W</td>
<td>L</td>
</tr>
<tr class="odd">
<td></td>
<td>b. LW1: /œ̃n+ami/</td>
<td>œ̃.na.mi ~ œ̃.ami</td>
<td>W</td>
<td></td>
<td>W</td>
<td>L</td>
</tr>
<tr class="even">
<td></td>
<td>c. NLW1: /ʒɔli+ami/</td>
<td>ʒɔli.ami ~ ʒɔ.lami</td>
<td>W</td>
<td></td>
<td>L</td>
<td>W</td>
</tr>
<tr class="odd">
<td></td>
<td><strong>d.&nbsp;NLW1: /ʒœn+bebe/</strong></td>
<td><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td><strong>W</strong></td>
<td><strong>L</strong></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>√</td>
<td><strong>e. LW1: /lez+bebe/</strong></td>
<td><strong>le.bebe ~ lez.bebe</strong></td>
<td><strong>L</strong></td>
<td><strong>W</strong></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>√</td>
<td>f. LW1: /œ̃n+bebe/</td>
<td>œ̃.bebe ~ œ̃n.bebe</td>
<td>L</td>
<td>W</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Following the instruction in (17) to “clone the constraint that prefers Ws in all instances of the errors committed by the <strong>current grammar</strong> and index it to morphemes for which it prefers only Ws for those errors”, the learners can activate their bias favouring the errors made by the current grammar marked by √ when resolving the inconsistency. Therefore, they would clone the relevant constraint that prefers Ws for the errors made by the current grammar (<span class="smallcaps">NoC.C-L</span>) indexed to those morphemes /lez/ and /œ̃n/ as shown in (34). With the addition of the new constraint, now there is a constraint that prefers only Ws with no inconsistencies (<span class="smallcaps">NoC.C-L</span>), therefore that constraint(s) is ranked at the top stratum. After that, the errors (34e‒f) are successfully resolved and the reranking can proceed as usual resulting in the final grammar below in (35).</p>
<p>(35)</p>
<p>Liaison G2.2: <span class="smallcaps">No C.C-L2**, No C.C-L1* &gt;&gt; Max &gt;&gt; NoC.C, Align-L, NoV.V</span><br>
*L1: {/lez/}, **L2: {/œ̃n/}</p>
<p>Eventually the learner then merges the two No C.C-L constraints under one constraint in the final grammar as shown in (36).</p>
<p>(36)</p>
<p>Liaison Final G: No C.C-L* &gt;&gt; Max &gt;&gt; No C.C, No V.V, Align-L<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> *L: {/lez/, /œ̃n/}</p>
</section>
<section id="ordered-learning-trajectory---non-liaison-first" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="ordered-learning-trajectory---non-liaison-first"><span class="header-section-number">2.5.2</span> Ordered learning trajectory - Non-liaison first</h3>
<p>In this group of learners, the first part involves receiving two non-liaison morphemes while the second part includes the two liaison morphemes. In this manner, the initial evidence presented to learners based on what they encounter in the first block lacks any form of inconsistency.</p>
<p>In the <strong>first block</strong>, learners encounter evidence of the following set of non-liaison phrases: {ʒœn+bebe, ʒœn+ami, … &amp; ʒɔli+ami, ʒɔli+bebe, …}. Since the learning data does not contain alternations, the ideal learner is essentially only required to perform lexicon optimization and store underlying representations which are identical to the output. By the end of the first block, assuming an initial state bias from G0, the learner does make errors with examples such as [ʒœnbebe] or [ʒɔliami]<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> shown in (37).</p>
<p>(37)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">a.</th>
<th style="text-align: left;">/ʒœn/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">☹</td>
<td style="text-align: left;">[ʒœn.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">☞</td>
<td style="text-align: left;">[ʒœ.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">b.</th>
<th style="text-align: left;">/ʒɔli/+/ami/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">☹</td>
<td style="text-align: left;">[ʒɔli.ami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">☞</td>
<td style="text-align: left;">[ʒɔ.lami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<p>Based on the recent errors present in their error archive as exemplified in the table below in (38), they are required to rerank and update their highest-ranked constraints from the initial state in G0.</p>
<p>(38) Error archive with errors of the CG (NoC.C, NoV.V, Align-L &gt;&gt; Max)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Errors by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">a. NLW1: /ʒɔli+ami/</td>
<td style="text-align: left;">ʒɔli.ami ~ ʒɔ.lami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;">b. NL W1: /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.na.mi ~ ʒœ.ami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
</tr>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">c. NL W1: /ʒœn+bebe/</td>
<td style="text-align: left;">ʒœn.bebe ~ ʒœ.bebe</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
</tr>
</tbody>
</table>
<p>Due to the fact that both types of marked structures (V.V and C.C) as well as syllable misalignments are allowed in the output and the inputs remain the same in their outputs without any alternations, a reversal of the faithfulness and markedness constraints in the constraint hierarchy is bound to occur. Hence, the learner starting from G0, must update its grammar with a biased constraint demotion algorithm and in doing so all markedness constraints must be installed after Max, since none of them exclusively prefer Ws as shown in G1 (39).</p>
<p>(39)</p>
<p>Non-liaison G1: Max &gt;&gt; No C.C, No V.V, Align-L</p>
<p>In the <strong>second block</strong> of their learning, they are presented with the liaison morphemes only: {le+bebe, lez+ami, …, œ̃+bebe, œ̃n+ami, …}. It is crucial that the ideal learner establishes the semantic connection between the allomorphs and identifies the larger consonant-final allomorph /lez/ and /œ̃n/ as the underlying representation employing the heuristic that we introduced in section 2.4.2. Such a learner relying on a uniform input of /lez/ would make errors on phrases such as [lebebe] or [œ̃bebe] following the previous grammar in G1, shown in (40).</p>
<p>(40)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/lez/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[lez.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>☹</td>
<td style="text-align: left;">[le.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 11%">
<col style="width: 17%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/œ̃n/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[œ̃n.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>☹</td>
<td style="text-align: left;">[œ̃.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>These recent errors need to be present in the error archive. As the learners compile all evidence in the archive, they realize the necessity of addressing the ranking paradox between the morphemes belonging to the two classes of word1s. The table below, which includes all the errors, illustrates the minimal inconsistent pair that highlights the inconsistency (41c vs 41e) in bold—where the specific constraints (<span class="smallcaps">Max</span> and <span class="smallcaps">NoC.C</span>) exhibit the opposite preferences for the morphemes presented in the two blocks of the experiment. The learner is unable to continue the reranking process and to install any constraints at this juncture.</p>
<p>(41) Error archive with errors of the CG (<span class="smallcaps">Max &gt;&gt; No C.C, No V.V, Align-L</span>)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 12%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 14%">
</colgroup>
<tbody>
<tr class="odd">
<td>Errors by CG</td>
<td>Input</td>
<td>W ~ L</td>
<td><span class="smallcaps">Max</span></td>
<td><span class="smallcaps">NoC.C</span></td>
<td><span class="smallcaps">NoV.V</span></td>
<td><span class="smallcaps">Align-L</span></td>
</tr>
<tr class="even">
<td></td>
<td>a. NLW1: /ʒɔli+ami/</td>
<td>ʒɔli.ami ~ ʒɔ.lami</td>
<td>W</td>
<td></td>
<td>L</td>
<td>W</td>
</tr>
<tr class="odd">
<td></td>
<td>b. NL W1: /ʒœn+ami/</td>
<td>ʒœ.na.mi ~ ʒœ.ami</td>
<td>W</td>
<td></td>
<td>W</td>
<td>L</td>
</tr>
<tr class="even">
<td></td>
<td><strong>c.&nbsp;NL W1: /ʒœn+bebe/</strong></td>
<td><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td><strong>W</strong></td>
<td><strong>L</strong></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>√</td>
<td><strong>d.&nbsp;L W1: /lez+bebe/</strong></td>
<td><strong>le.bebe ~ lez.bebe</strong></td>
<td><strong>L</strong></td>
<td><strong>W</strong></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>√</td>
<td>e. L W1: /œ̃n+bebe/</td>
<td>œ̃.bebe ~ œ̃n.bebe</td>
<td>L</td>
<td>W</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Similar to the previous scenario, following the instruction in (17) the learners can take advantage of their bias favouring the errors made by the current grammar marked by √ when resolving the inconsistency. Therefore, they would clone the relevant constraint that prefers Ws for the errors made by the current grammar (<span class="smallcaps">NoC.C-L</span>) indexed to those morphemes /lez/ and /œ̃n/. As shown in (42) <span class="smallcaps">NoC.C-L</span> is the only markedness constraint that prefers only Ws, therefore, it is ranked at the top. After that, the errors (d-e) are resolved and the reranking can proceed as usual resulting in the final grammar below in G2.</p>
<p>(42)</p>
<p>Non-liaison G2: <span class="smallcaps">NoC.C-L2**, NoC.C-L1* &gt;&gt; Max &gt;&gt; NoC.C, Align-L, NoV.V</span><br>
*L1: {/lez/}, **L2: {/œ̃n/}</p>
<p>Eventually the learner then merges the two <span class="smallcaps">NoC.C-L</span> constraints under one constraint in the final grammar as shown in (43).</p>
<p>(43)</p>
<p>Non-liaison Final G: <span class="smallcaps">NoC.C-L* &gt;&gt; Max &gt;&gt; NoC.C, NoV.V, Align-L</span> *L: {/lez/, /œ̃n/}</p>
</section>
<section id="mixed-learning-trajectory" class="level3" data-number="2.5.3">
<h3 data-number="2.5.3" class="anchored" data-anchor-id="mixed-learning-trajectory"><span class="header-section-number">2.5.3</span> Mixed Learning trajectory</h3>
<p>For this group of learners, the learning data of the 2 morpheme types is not presented in an isolated manner, rather they see both types of morphemes at the same time: one liaison morpheme and one non-liaison morpheme. In this manner, the first type of evidence presented to learners based on what they encounter in the first block, would in fact present an inconsistency to learners.</p>
<p>In the <strong>first block</strong>, learners encounter evidence of the following set of liaison and non-liaison phrases: {le+bebe, lez+ami, … &amp; ʒœn+bebe, ʒœn+ami, …}. The learner’s task is slightly different in nature here. An ideal learner needs to first recognize the crucial difference between these two morphemes, namely that one of them lacks a stable output form and exhibits an alternation. The representations of non-liaison morphemes can be learned through lexicon optimization. However, once the learner identifies that one of the morphemes is special in that it has two output forms with some established semantic connection, they need to employ the proposed heuristic to maximize the structure in the input. Thus, they determine the larger allomorph /lez/ to be the underlying representation. Phrases such as [lebebe] and [lezami] do not cause errors at first. However, by the end of the first block, assuming an initial state bias from G0, the learner does make errors with examples such as [ʒœnbebe] or [ʒœnami]<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> show in tableaux in (44).</p>
<p>(44)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">a.</th>
<th style="text-align: left;">/ʒœn/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">☹</td>
<td style="text-align: left;">[ʒœn.bebe]</td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">☞</td>
<td style="text-align: left;">[ʒœ.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 11%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">b.</th>
<th style="text-align: left;">/ʒœn/+/ami/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">☹</td>
<td style="text-align: left;">[ʒœn.ami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">☞</td>
<td style="text-align: left;">[ʒœ.ami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
</tbody>
</table>
<p>At this stage, the input forms such as /lez/ and /bebe/ and /ami/ directly enter the lexicon of the learner as there are no errors made on them. However, the phrase leading to the error in (44) has to be moved to the error archive as shown in table (45) below. Now, based on the recent errors present in their error archive marked by √ they are required to rerank and update their highest-ranked constraints from the initial state in G0.</p>
<p>(45) Error archive with errors of the CG (NoC.C, NoV.V, Align-L &gt;&gt; Max)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Errors by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">No C.C</span></th>
<th style="text-align: left;"><span class="smallcaps">No V.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">a. NLW1: /ʒœn+bebe/</td>
<td style="text-align: left;">ʒœn.bebe ~ ʒœ.bebe</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;">b. NLW1: /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.nami ~ ʒœ.ami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
</tr>
</tbody>
</table>
<p>Due to the fact that marked structures including C.C are allowed, the relevant markedness constraint is preferred by Ls. The biased constraint demotion would initiate the reranking of initial state markedness constraints outranking other constraints at the top. Consequently, among the possible markedness constraints, the learner must install No V.V as the only markedness constraint that prefers only Ws once the relevant row of error in (45b) is resolved shown in (46).</p>
<p>(46) Error archive with errors of the CG (NoC.C, NoV.V, Align-L &gt;&gt; Max)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 15%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Errors by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">No C.C</span></th>
<th style="text-align: left;"><span class="smallcaps">No V.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;">a. NLW1: /ʒœn+bebe/</td>
<td style="text-align: left;">ʒœn.bebe ~ ʒœ.bebe</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;"><del>√</del></td>
<td style="text-align: left;"><del>b. NLW1: /ʒœn+ami/</del></td>
<td style="text-align: left;"><del>ʒœ.nami ~ ʒœ.ami</del></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><del>W</del></td>
<td style="text-align: left;"><del>L</del></td>
<td style="text-align: left;"><del>W</del></td>
</tr>
</tbody>
</table>
<p>As the rest of the reranking algorithm continues based on (46a), the next markedness constraint that prefers no losers is Align-L, therefore it is placed in the second stratum which outranks Max. The final step installs NoC.C at the bottom as it prefers Ls as shown in G1 (47).</p>
<p>(47)</p>
<p>Mix G1: <span class="smallcaps">No V.V &gt;&gt; Align-L &gt;&gt; Max &gt;&gt; No C.C</span></p>
<p>Once the learners form the hierarchy in G1, they would immediately make errors with the phrases including the other word1 in this block, which is a liaison word1, shown in a tableau in (48) such as [lebebe].</p>
<p>(48)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 16%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/lez/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">NOV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NOC.C</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[lez.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
</tr>
<tr class="even">
<td>☹</td>
<td style="text-align: left;">[le.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>This recent error needs to be recorded in the error archive shown in (49c). As the learners compile all evidence from errors they learned from in this block, they realize the necessity of addressing the ranking paradox between the morphemes belonging to the two word1s they encountered in this block. The table below in (49), illustrates the minimal inconsistent pair that highlights the inconsistency (49b vs 49c) in bold. The learner is unable to continue the reranking process and to install any constraints.</p>
<p>(49) Error archive with errors of the CG (<span class="smallcaps">No V.V &gt;&gt; Align-L &gt;&gt; Max &gt;&gt; No C.C</span>)</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 16%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Errors by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;"><span class="smallcaps">No V.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">No C.C</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">a. NL W1: /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.nami ~ ʒœ.ami</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>b. NL W1: /ʒœn+bebe/</strong></td>
<td style="text-align: left;"><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>W</strong></td>
<td style="text-align: left;"><strong>L</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;">√</td>
<td style="text-align: left;"><strong>c.&nbsp;L W1: /lez+bebe/</strong></td>
<td style="text-align: left;"><strong>le.bebe ~ lez.bebe</strong></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"><strong>L</strong></td>
<td style="text-align: left;"><strong>W</strong></td>
</tr>
</tbody>
</table>
<p>In the event of detecting an inconsistency among constraints’ Ws and Ls, following the instruction in (17) the learners can take advantage of their bias favouring the errors made by the current grammar to resolving the inconsistency. Therefore, they would clone the relevant constraint that prefers Ws for the errors made by the current grammar indexed to that morpheme /lez/ (<span class="smallcaps">No C.C-L</span>). The new added constraint, <span class="smallcaps">NoC.C-L,</span> is the only markedness constraint that prefers only Ws. Therefore, according to the biased constraint demotion algorithm it is ranked at the top stratum. After the error (49c) is resolved, the reranking can proceed as usual (similar to the steps 45‒47) resulting in the grammar G1.2 below in (50).</p>
<p>(50)</p>
<p>Mix G1.2: No C.C-L* &gt;&gt; No V.V &gt;&gt; Align-L &gt;&gt; Max &gt;&gt; No C.C *L: {/lez/}</p>
<p>In the <strong>second block</strong> of the experiment, participants encounter the other liaison and non-liaison morphemes: {œ̃+bebe, œ̃n+ami, … &amp; ʒɔli +ami, ʒɔli +bebe, …}. This block shares some similarities with the first block but also presents some new challenges. Similar to before, they must distinguish the inconsistency between the new liaison word1s from the new non-liaison word1s. For the liaison word1s, the ideal learner must connect the two allomorphs semantically and identify the larger allomorph as the underlying representation. The novelty in this block of the experiment goes beyond simply recognizing the inconsistencies within the grammar. It also involves the learners’ ability to classify the new liaison word alongside /lez/ and the new non-liaison words with /ʒɔli/. However, the learners begin this block by making errors with /ʒɔli/<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>, as the <span class="smallcaps">NoV.V</span> constraint is highly ranked in G1.2 shown in the tableau in (51).</p>
<p>(51)</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 10%">
<col style="width: 17%">
<col style="width: 15%">
<col style="width: 17%">
<col style="width: 14%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/ʒɔli/+/ami/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C-L</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[ʒɔli.ami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>☹</td>
<td style="text-align: left;">[ʒɔ.lami]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>This recent error (51) needs to be present in the error archive, as shown in (52d). Once this new error is recorded, the learner is required to rerank and update their constraint hierarchy from the previous grammar.</p>
<p>(52) Error archive with errors of the CG (No C.C-L* &gt;&gt; No V.V &gt;&gt; Align-L &gt;&gt; Max &gt;&gt; No C.C)</p>
<table class="table">
<colgroup>
<col style="width: 13%">
<col style="width: 21%">
<col style="width: 19%">
<col style="width: 9%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Errors by CG</th>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">W ~ L</th>
<th style="text-align: left;">No C.C-L</th>
<th style="text-align: left;">No C.C</th>
<th>No V.V</th>
<th style="text-align: left;">Align-L</th>
<th style="text-align: left;">Max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">a. NL W1: /ʒœn+ami/</td>
<td style="text-align: left;">ʒœ.nami ~ ʒœ.ami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td>W</td>
<td style="text-align: left;">L</td>
<td style="text-align: left;">W</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;">b. NL W1: /ʒœn+bebe/</td>
<td style="text-align: left;">ʒœn.bebe ~ ʒœ.bebe</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
<td></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">W</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">c. L W1: /lez+bebe/</td>
<td style="text-align: left;">le.bebe ~ lez.bebe</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">W</td>
<td></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">L</td>
</tr>
<tr class="even">
<td style="text-align: left;">√</td>
<td style="text-align: left;">d. NLW1: /ʒɔli+ami/</td>
<td style="text-align: left;">ʒɔli.ami ~ ʒɔ.lami</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td>L</td>
<td style="text-align: left;">W</td>
<td style="text-align: left;">W</td>
</tr>
</tbody>
</table>
<p>According to the biased constraint demotion algorithm, No C.C-L is still ranked at the top stratum since it is the only constraint that prefers only Ws. No other markedness constraints prefer only Ws, therefore Max outranks them as the grammar G2 below shows in (53).</p>
<p>(53)</p>
<p>Mix G2: <span class="smallcaps">No C.C* &gt;&gt; Max &gt;&gt; No C.C, Align-L, No V.V</span> *L: {/lez/}</p>
<p>Importantly, for this particular learner, the highest ranked <span class="smallcaps">NoC.C-L</span> constraint is only associated with /lez/. Consequently, leading the learner to initially make errors when confronted with the new liaison word /œ̃n/ as shown in a tableau in (54).</p>
<p>(54)</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 10%">
<col style="width: 17%">
<col style="width: 14%">
<col style="width: 15%">
<col style="width: 15%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">/œ̃n/+/bebe/</th>
<th style="text-align: left;"><span class="smallcaps">NoC.C-L</span></th>
<th style="text-align: left;"><span class="smallcaps">Max</span></th>
<th style="text-align: left;"><span class="smallcaps">NoC.C</span></th>
<th style="text-align: left;"><span class="smallcaps">NoV.V</span></th>
<th style="text-align: left;"><span class="smallcaps">Align-L</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>☞</td>
<td style="text-align: left;">[œ̃n.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>☹</td>
<td style="text-align: left;">[œ̃.bebe]</td>
<td style="text-align: left;"></td>
<td style="text-align: left;">*!</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>This recent error (54) needs to be recorded in the error archive shown in (55e). Similar to the other errors previously, once this new error is added to the error archive, they are required to update their constraint hierarchy.</p>
<p>(55) Error archive with errors of the CG (<span class="smallcaps">No C.C* &gt;&gt; Max &gt;&gt; No C.C, Align-L, No V.V</span>)</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 9%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 8%">
</colgroup>
<tbody>
<tr class="odd">
<td>Errors by CG</td>
<td>Input</td>
<td>W ~ L</td>
<td>No C.C-L</td>
<td>Max</td>
<td>No C.C</td>
<td>No V.V</td>
<td>Align-L</td>
</tr>
<tr class="even">
<td></td>
<td><ol type="a">
<li>NLW1: /ʒœn+ami/</li>
</ol></td>
<td>ʒœna.mi ~ ʒœ.ami</td>
<td></td>
<td>W</td>
<td></td>
<td>W</td>
<td>L</td>
</tr>
<tr class="odd">
<td></td>
<td><strong>b. NLW1: /ʒœn+bebe/</strong></td>
<td><strong>ʒœn.bebe ~ ʒœ.bebe</strong></td>
<td></td>
<td><strong>W</strong></td>
<td><strong>L</strong></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td>c. LW1: /lez+bebe/</td>
<td>le.bebe ~ lez.bebe</td>
<td>W</td>
<td>L</td>
<td>W</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>d. NLW1: /ʒɔli+ami/</td>
<td>ʒɔli.ami ~ ʒɔ.lami</td>
<td></td>
<td>W</td>
<td></td>
<td>L</td>
<td>W</td>
</tr>
<tr class="even">
<td>√</td>
<td><strong>e. LW1: /œ̃n+bebe/</strong></td>
<td><strong>œ̃.bebe ~ œ̃n.bebe</strong></td>
<td></td>
<td><strong>L</strong></td>
<td><strong>W</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>The learner is unable to continue the&nbsp;reranking procedure as the errors in (54b vs 54e) are in conflict and there are no constraints that prefer only Ws. At this juncture, following the instruction in (17) their errors made by the current grammar can bias the learners when resolving the inconsistency. Therefore, they would clone the relevant constraint that prefers Ws for the errors made by the current grammar indexed to that morpheme /œ̃n/ (No C.C-L). This results in two cloned constraints as it is shown in the hierarchy below in (56).</p>
<p>(56)</p>
<p>Mix G2.2: <span class="smallcaps">NoC.C-L2**, NoC.C-L1* &gt;&gt; Max &gt;&gt; NoC.C, Align-L, NoV.V<br>
</span> *L1: {/lez/}, **L2: {/œ̃n/}</p>
<p>However, it is expected that in such a situation these cloned constraints would merge; resulting in a single constraint being indexed to both morphemes instead as shown below in the final grammar in (57):</p>
<p>(57)</p>
<p>Mix final G: <span class="smallcaps">NoC.C-L* &gt;&gt; Max &gt;&gt; NoC.C, Align-L, NoV.</span>V *L: {/lez/, /œ̃n/}</p>
</section>
<section id="predicted-outcomes-of-trajectories" class="level3" data-number="2.5.4">
<h3 data-number="2.5.4" class="anchored" data-anchor-id="predicted-outcomes-of-trajectories"><span class="header-section-number">2.5.4</span> Predicted outcomes of trajectories</h3>
<p>In this subsection, the predicted outcomes of the hypothesized trajectories are outlined. First, a summary of the trajectory of ideal learners who learned the artificial language through three different ordering of learning data is shown in the following Table 2-1. The three groups have the same initial state (G0) and end state (GE), but they differ in the order of learning data and thus also in their trajectories shaped in the two blocks. The constraint hierarchies built in the first block are shown as G1 and the constraint hierarchies build in the second block are shown as G2. If a block has more than one constraint hierarchy they are separated by a dashed line for clarity.</p>
<p>There are several aspects in which these ideal learners can be evaluated on, including: a. underlying representations, b. reranking of the constraint hierarchy, c.&nbsp;lexicon indexation, and d.&nbsp;constraint cloning. In the following subsection on predictions, I will review the theoretical pressures pertaining to an ideal learner for each aspect individually. It is important to note that the cognitive and memory constraints associated with each of these trajectories could impact learners’ performance in various ways in experimental settings, a topic I will address under the pressures faced by a suboptimal learner in the last subsection.</p>
<p>In the experiment, after being presented with the learning data, participants engage in a series of forced choice tasks. The tasks are comparable to selecting between pairs of winning and losing candidates. By quantifying their accuracy with forced-choice tasks, making inferences about their learning is also possible through analyzing their errors. The main research question targets the difficulty of learning morpheme-specific alternations along certain theoretical dimensions which are included in a theory of learning within OT. Given that the only manipulation for these groups of participants is the distribution and order of learning input, I hypothesize that there will be differences in the difficulty of learning which would lead to differential learning outcomes in two respects simultaneously: quantitatively, and qualitatively, that is, in terms of overall differences across the groups, and the distribution of errors within each group, respectively.</p>
<p>Table <strong>Error! No text of specified style in document.</strong>‑1. The summary of learning trajectories of the three groups of learners</p>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 36%">
<col style="width: 15%">
<col style="width: 36%">
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td><strong>Liaison First</strong></td>
<td><strong>Non-liaison First</strong></td>
<td><strong>Mixed</strong></td>
</tr>
<tr class="even">
<td><p><strong>Initial state</strong></p>
<p><strong>(G0 )</strong></p></td>
<td><p><strong>No C.C, No V.V, Align-L</strong></p>
<p><strong>&gt;&gt; Max</strong></p></td>
<td><p><strong>No C.C, No V.V, Align-L</strong></p>
<p><strong>&gt;&gt; Max</strong></p></td>
<td><p><strong>No C.C, No V.V, Align-L</strong></p>
<p><strong>&gt;&gt; Max</strong></p></td>
</tr>
<tr class="odd">
<td><strong>Block1<br>
(G1 )</strong></td>
<td><p>No C.C, No V.V</p>
<p>&gt;&gt; Align-L</p>
<p>&gt;&gt; Max</p></td>
<td><p>Max</p>
<p>&gt;&gt; No C.C, No V.V, Align-L</p></td>
<td><p>No V.V</p>
<p>&gt;&gt; Align-L</p>
<p>&gt;&gt; Max</p>
<p>&gt;&gt; No C.C</p>
<p>-<br>
———<br>
———-</p>
<p>No C.C-L*</p>
<p>&gt;&gt; No V.V</p>
<p>&gt;&gt; Align-L</p>
<p>&gt;&gt; Max</p>
<p>&gt;&gt; No C.C</p>
<p>*L: {/lez/}</p></td>
</tr>
<tr class="even">
<td><strong>Block2<br>
(G2 )</strong></td>
<td><p>Max</p>
<p>&gt;&gt; No C.C, No V.V, Align-L</p>
<hr>
<p>No C.C-L**, No C.C-L*</p>
<p>&gt;&gt; Max</p>
<p>&gt;&gt; No C.C, No</p>
<p>V.V, Align-L</p>
<p>**L: {/œ̃n/} *L: {/lez/}</p></td>
<td><p>No C.C-L**, No C.C-L*</p>
<p>&gt;&gt; Max</p>
<p>&gt;&gt; No C.C, No</p>
<p>V.V, Align-L</p>
<p>**L: {/œ̃n/} *L: {/lez/}</p></td>
<td><p>No C.C-L*</p>
<p>&gt;&gt; Max</p>
<p>&gt;&gt; No C.C, No</p>
<p>V.V, Align-L</p>
<p>*L: {/lez/}</p>
<hr>
<p>No C.C-L**, No C.C-L*</p>
<p>&gt;&gt; Max</p>
<p>&gt;&gt; No C.C, No</p>
<p>V.V, Align-L</p>
<p>**L: {/œ̃n/} *L: {/lez/}</p></td>
</tr>
<tr class="odd">
<td><p><strong>End state</strong></p>
<p><strong>(GE )</strong></p></td>
<td><p><strong>No C.C-L*</strong></p>
<p><strong>&gt;&gt; Max</strong></p>
<p><strong>&gt;&gt; No C.C, No</strong></p>
<p><strong>V.V, Align-L<br>
*L: {/lez/, /œ̃n/}</strong></p></td>
<td><p><strong>No C.C-L*</strong></p>
<p><strong>&gt;&gt; Max</strong></p>
<p><strong>&gt;&gt; No C.C, No</strong></p>
<p><strong>V.V, Align-L<br>
*L: {/lez/, /œ̃n/}</strong></p></td>
<td><p><strong>No C.C-L*</strong></p>
<p><strong>&gt;&gt; Max</strong></p>
<p><strong>&gt;&gt; No C.C, No V.V,</strong></p>
<p><strong>Align-L *L: {/lez/, /œ̃n/}</strong></p></td>
</tr>
</tbody>
</table>
<section id="predictions-for-an-optimal-learner" class="level4">
<h4 class="anchored" data-anchor-id="predictions-for-an-optimal-learner">Predictions for an optimal learner</h4>
<section id="underlying-representations-in-alternations" class="level5">
<h5 class="anchored" data-anchor-id="underlying-representations-in-alternations">Underlying representations in alternations</h5>
<p>The ideal learning of morpho-phonological patterns begins with the creation of underlying representations for new morphemes. In the experiment, all learners must understand that two of the four morphemes, described as liaison morphemes, share a single input corresponding to two output variants. Then they can posit the correct underlying representation using the heuristic. The rationale is that if the type of data and the order in which learning data is presented influences the&nbsp;learning of the underlying representations of alternations, there would be differences among the groups’ accuracy reflective of that. Specifically, learners who follow the liaison-first trajectory face less challenges to compute the underlying representations of the allomorphs. This is because the initial evidence of both liaison morphemes they receive in the first block will facilitate their understanding of the 2-1 mapping from output to input, rather than relying on secondary or inconsistent evidence. Conversely, learners in the non-liaison-first trajectory would find it more challenging, because they lost the clear opportunity in the very beginning to learn about the phonologically motivated alternations in the mini-language. This might hinder their ability to notice the alternations and thereby establish a unified input through the heuristic. The unordered group, on the other hand, has access to only one liaison morpheme learning data compared to the liaison-first group in the first block, placing them in an intermediate difficulty position.</p>
<p>Therefore, this rationale for learning the underlying representation predicts the following order of learning difficulty among the groups, from easiest to hardest:</p>
<p>liaison-first &gt; unordered &gt; non-liaison-first</p>
</section>
<section id="reranking-of-the-constraint-hierarchy" class="level5">
<h5 class="anchored" data-anchor-id="reranking-of-the-constraint-hierarchy">Reranking of the constraint hierarchy</h5>
<p>During the morpho-phonological learning process driven by errors, once a learner has explored the possible underlying representations and selected the appropriate one, the next step involves reranking the constraints until reaching a final state grammar without errors. The rationale is that if the order in which learning data is presented influences the trajectory and steps of constraint reranking, the differences in performance across the groups would reflect that. In principle, the hypothesis is that having fewer stages of reranking is easier. That means, learners following a non-liaison-first trajectory are expected to find it easier to converge on the end state grammar. This is because they only need to update and rerank their constraint hierarchy twice to arrive at the correct end state grammar, whereas other groups require more reranking stages.</p>
<p>Therefore, this rationale about reaching the end state grammar predicts the following order of learning among the groups from easiest to hardest:</p>
<p>non-liaison-first &gt; liaison-first &gt; unordered</p>
</section>
<section id="lexicon-indexation-and-constraint-cloning" class="level5">
<h5 class="anchored" data-anchor-id="lexicon-indexation-and-constraint-cloning">Lexicon indexation and constraint cloning</h5>
<p>The next crucial aspect of learning morpheme-specific alternations involves identifying inconsistencies in the grammar and acknowledging that certain morphemes within a subset of the lexicon may conflict with their current ranking. I predict that in scenarios requiring inconsistency detection, if the process of learning lexicon indexation varies depending on the order and type of learning data presented, the differences in performance among groups would be reflective of that. Specifically, the hypothesis is that it is easier for learners to recognize that a group of morphemes must be indexed to specific constraints when they are exposed to multiple morphemes of the same class in each block. Consequently, the two ordered groups would find it easier to choose indexations compared to the unordered group. The unordered group, in contrast, must learn that some morphemes require indexing twice, in the first and second blocks of the experiment.</p>
<p>Furthermore, learners need to determine which constraints to clone and index to a subset of the lexicon. Echoing the previous argument on lexicon indexation, I predict that recognizing when a constraint needs to be cloned and indexed is more straightforward when learners encounter the set of morphemes in a class together. Moreover, this expectation also arises from the fact that the ordered groups can integrate their cloned versions of the constraints for each instance of the liaison morphemes as they generate them simultaneously, while the unordered group must grapple with this decision once more later as they have cloned their constraints in two separate blocks.</p>
<p>Therefore, this rationale for constraint cloning and lexicon indexation predicts the following order of learning among the groups from easiest to hardest:</p>
<p>non-liaison-first, liaison-first &gt; unordered</p>
</section>
<section id="distribution-of-errors-within-each-group" class="level5">
<h5 class="anchored" data-anchor-id="distribution-of-errors-within-each-group">Distribution of errors within each group</h5>
<p>I also predict that the learning and performance of the three groups would differ qualitatively with each other, namely with respect to the type of errors that they frequently make. If the difficulties of learning are not of the same nature for the three groups, their error patterns will show differences in learning. Specifically, each group will make less errors with the type of phrases presented to them in their first block compared to the second block.</p>
<p>Therefore, if the order of receiving the input affects their learning, it is easier to learn liaison phrases for the liaison-first group compared to the other groups and it is easier to learn non-liaison phrases for the non-liaison-first group compared to the other groups.</p>
</section>
</section>
<section id="predictions-for-a-suboptimal-learner" class="level4">
<h4 class="anchored" data-anchor-id="predictions-for-a-suboptimal-learner">Predictions for a suboptimal learner</h4>
<p>There are various ways in which in an experimental setting the learner might face extra limitations due to memory or cognitive load of the tasks. The first issue could be influenced by restraints on memory and its connection to the storage of the&nbsp;lexicon and the error archive. For instance, during block two of the experiment, the liaison-first group has to recall from memory that certain inputs that were learned in the first block without any errors, would lead to errors with their updated grammar at that stage. In this scenario, a suboptimal learner in an experimental setting might find it more difficult to hold the words and phrases in the language in memory for a longer time to consider their errors and non-errors as they progress in the experiment towards the end.</p>
<p>This rationale for possible memory constraints leads to the predictions that the difficulty among groups ranked from easiest to hardest are as follows:</p>
<p>non-liaison-first &gt; liaison-first, unordered</p>
<p>Another cognitively challenging aspect of learning concerns the cost of learning generalizations and lexical optimization sequentially. If a learner has to learn morpheme-specific alternations in an inconsistent grammar, they must learn two things: a) simple phonologically-motivated generalization supported by a&nbsp;universal bias towards unmarked structures and b) more complicated lexical facts. Hsu and Chater (2010) propose a simplicity-based cognitive model for the logical problem of language acquisition where there is a trade-off in the costs of learning a simple generalization with less data and learning lexical and more complicated rules with more data. Inspired by the ideas in the simplicity framework, I hypothesize that cost of learning from an inconsistent set of learning data in the direction which the learner retreats from a generalization to lexicon optimization through receiving more evidence would be lower than learning in the opposite direction, from lexicon optimization to a generalization about alternations.</p>
<p>Consequently, this rationale about the cognitive costs of the learning trajectory predicts the following order of difficulty among the groups from easiest to hardest:</p>
<p>liaison-first &gt; non-liaison-first, unordered.</p>
<table class="table">
<caption>Table 2‑2. The summary of predictions of difficulty of learning by different aspects</caption>
<colgroup>
<col style="width: 33%">
<col style="width: 27%">
<col style="width: 23%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: left;">easiest</th>
<th></th>
<th style="text-align: left;">hardest</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>UR of alternations</td>
<td style="text-align: left;">liaison-1st &gt;</td>
<td>unordered &gt;</td>
<td style="text-align: left;">non-liaison-1st</td>
</tr>
<tr class="even">
<td>Reranking of the constraint hierarchy</td>
<td style="text-align: left;">non-liaison-1st &gt;</td>
<td>liaison-1st &gt;</td>
<td style="text-align: left;">unordered</td>
</tr>
<tr class="odd">
<td>Lexicon indexation + constraint cloning</td>
<td style="text-align: left;">liaison-1st, non-liaison-1st &gt;</td>
<td></td>
<td style="text-align: left;">unordered</td>
</tr>
<tr class="even">
<td>Learning liaison patterns</td>
<td style="text-align: left;">liaison-1st &gt;</td>
<td>non-liaison-1st, unordered</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td>Learning non-liaison patterns</td>
<td style="text-align: left;">non-liaison-1st &gt;</td>
<td>liaison-1st, unordered</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td>memory constraints</td>
<td style="text-align: left;">non-liaison-1st &gt;</td>
<td>liaison-1st, unordered</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td>cognitive costs</td>
<td style="text-align: left;">liaison-1st &gt;</td>
<td>non-liaison-1st, unordered</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>To summarize the predictions in this subsection, Table 2-2 shows the different groups ranked in the order of difficulty for each prediction. The predictions about the difficulty of learning with respects to various aspects could be evaluated by examining the performance differences among the three groups during testing.</p>
<p>In the next chapter, the experimental design, material, and training and testing procedures are described in more detail.</p>


</section>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>The facts about the acquisition of the past tense allomorphs in English are more complicated than presented here schematically with two of the forms (see Tomas et al., 2017; Oetting and Horohov, 1997).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>See Kager (2004: 330-336) for an example of a learner with a morphological handicap which shows that the algorithm would still converge when learning the voicing alternation in plural morphemes in Dutch.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>No V.V: Mark a violation if two hetero-syllabic vowels are adjacent (V.V).<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>No C.C: Mark a violation if two hetero-syllabic consonants are adjacent (C.C).<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Align-L: Mark a violation if the left edge of a morphological word does not coincide with the left edge of a prosodic word (Kager, 2004: 111).<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Max: Mark a violation if every segment in the input does not have a corresponding segment in the output.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Dep: Mark a violation if every segment in the output does not have a corresponding segment in the input.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>This constraint would be accessible in phrases where morphological knowledge is acquired. Learners have to know the prosodic word with a syllabification of /n/ for an output such as [ʒœ.#na.mi] is not aligned with the morphological boundaries in the output [ʒœ.n#a.mi].<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>It is worth mentioning that the literature is non-conclusive regarding this general criterion, so testing this heuristic in this specific domain needs further experimental investigation. The past literature in OT on what possible constraints can exist in Con has put forward a constraint family known as *Struc (Prince and Smolensky, 1993) which has a “less is best” spirit. In this situation it would mean selecting the other possible input in CV form to be the underlying representation as it is structurally less complex. However, this view is not the established view in the literature as Gouskova (2003) has shown in her work.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Choosing the smaller allomorph as the input, entails that the learner has to choose a grammar that ranks No V.V &gt;&gt; Dep. In this grammar, generating the other allomorph necessitates inserting the final consonant (LC) which makes the phonological learner reach a dead-end very soon, since it eventually becomes evident that each morpheme requires insertion of an arbitrary consonant. For instance, for the masculine singular indefinite article <em>un</em> a hypothetical learner could choose the nasal segment /n/ to be inserted because the vowel is nasalized. However, by inserting the same nasal segment in the plural definite morpheme <em>les</em> the learner would be making an error.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>The idea is that all errors are permanently stored in the error archive; however, for space reasons, errors in (11a) and (11d) are not displayed since Dep is no longer included in the constraint set.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>I am assuming that the indexed constraints follow a locality principle and only apply locally to the morpheme indexed, here /lez/, and not to the full word1+word2 input.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>The underlying assumption is that when the three markedness constraints are ranked equally at the top in the initial state, it essentially corresponds to maintaining six different permutations, such as A &gt; B &gt; C, A &gt; C &gt; B, and so forth. In the permutation that features <span class="smallcaps">Align-L &gt; NoV.V</span>, learners would be making such errors shown in (27b).<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Recall that other faithfulness constraints such as <span class="smallcaps">Dep</span> are not shown in this hierarchy due to reasons of space but it is at the same stratum as <span class="smallcaps">Max</span>, outranking <span class="smallcaps">NoV.V</span>.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Same as the previous footnote, when the three markedness constraints are ranked equally at the top in the initial state, it essentially corresponds to maintaining six different permutations, such as A &gt; B &gt; C, A &gt; C &gt; B, and so forth. In the permutation that features NOV.V&gt;&gt;ALIGN-L, ultimately learners would be making such errors as shown in (36b).<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Same as the previous footnotes, when the three markedness constraints are ranked equally at the top in the initial state, in the permutation that features ALIGN-L &gt;&gt; NOV.V, ultimately learners would be making such errors as shown in (43b).<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>This order of errors is specific to this version. There are in fact two versions of the unordered group in the experiment to counterbalance the effect of specific errors. The other version of this trajectory would be to receive /ʒɔli/ in the first block and /ʒœn/ in the second block. This difference does not affect how many stages of G there would be overall, but it is worth mentioning that the other version not reviewed here leads to a different error at this point with [ʒœnbebe].<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/gazellarium\.github\.io\/thesis25");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/1_introduction.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/3_methods.html" class="pagination-link" aria-label="Methods">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Methods</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>